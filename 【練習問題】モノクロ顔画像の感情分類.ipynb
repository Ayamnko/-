{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPvEYGT5XC4j5od0cPncpm+"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "ルール違反ではないので手動でtest_master.tsvを作るのはあり"
      ],
      "metadata": {
        "id": "5oyEj1FoG-tB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "0xZZxmD-3Aqo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5008b26a-926a-425f-b287-8850541c2f02"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "['train.zip', 'test.zip', 'train_master.tsv', '.ipynb_checkpoints', '【練習問題】モノクロ顔画像の感情分類']\n",
            "               id  userid  pose  expression  eyes\n",
            "0  train_0000.jpg       6     2           0     0\n",
            "1  train_0001.jpg      11     2           0     0\n",
            "2  train_0002.jpg      15     1           1     1\n",
            "3  train_0003.jpg      10     0           2     1\n",
            "4  train_0004.jpg       0     0           3     1\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import os\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "import zipfile\n",
        "from io import BytesIO\n",
        "import numpy as np\n",
        "from google.colab import drive\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "\n",
        "# Google Driveをマウント\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Google Drive内のファイルリストを確認\n",
        "file_list = os.listdir('/content/drive/My Drive/Colab Notebooks/【練習問題】モノクロ顔画像の感情分類')\n",
        "print(file_list)\n",
        "\n",
        "# train_master.tsv の読み込み\n",
        "train_master_path = '/content/drive/My Drive/Colab Notebooks/【練習問題】モノクロ顔画像の感情分類/train_master.tsv'\n",
        "train_master = pd.read_csv(train_master_path, sep='\\t')\n",
        "\n",
        "\n",
        "\n",
        "# ラベルエンコーダーのインスタンスを作成\n",
        "le = LabelEncoder()\n",
        "\n",
        "# 各列に対してラベルエンコーディングを実行\n",
        "train_master['userid'] = le.fit_transform(train_master['userid'])\n",
        "train_master['pose'] = le.fit_transform(train_master['pose'])\n",
        "train_master['eyes'] = le.fit_transform(train_master['eyes'])\n",
        "\n",
        "# 置換マッピングを定義\n",
        "replace_dict = {'angry': 0, 'sad': 1, 'neutral': 2, 'happy': 3}\n",
        "\n",
        "# 置換処理\n",
        "train_master['expression'] = train_master['expression'].replace(replace_dict)\n",
        "\n",
        "print(train_master.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ベーシックなモデル\n",
        "import zipfile\n",
        "from PIL import Image\n",
        "from io import BytesIO\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# データの読み込み\n",
        "def load_data(label_col):\n",
        "    with zipfile.ZipFile(train_zip_path, 'r') as z:\n",
        "        image_files = z.namelist()\n",
        "        images = []\n",
        "        labels = []\n",
        "\n",
        "        for index, row in train_master.iterrows():\n",
        "            file_name = 'train/' + row['id']\n",
        "            if file_name in image_files:\n",
        "                with z.open(file_name) as img_file:\n",
        "                    img = Image.open(BytesIO(img_file.read()))\n",
        "                    img = img.resize((128, 120))\n",
        "                    img = np.array(img)\n",
        "                    images.append(img)\n",
        "                    labels.append(row[label_col])\n",
        "\n",
        "    X = np.array(images)\n",
        "    y = np.array(labels)\n",
        "    X = X / 255.0\n",
        "    return X, y\n",
        "\n",
        "# モデルの構築と訓練\n",
        "def build_and_train_model(X, y, num_classes, epochs):\n",
        "    y_categorical = to_categorical(y, num_classes=num_classes)\n",
        "\n",
        "    model = Sequential([\n",
        "        Conv2D(32, (3, 3), activation='relu', input_shape=(128, 120, 1)),\n",
        "        MaxPooling2D((2, 2)),\n",
        "        Conv2D(64, (3, 3), activation='relu'),\n",
        "        MaxPooling2D((2, 2)),\n",
        "        Conv2D(128, (3, 3), activation='relu'),\n",
        "        MaxPooling2D((2, 2)),\n",
        "        Flatten(),\n",
        "        Dense(128, activation='relu'),\n",
        "        Dense(num_classes, activation='softmax')\n",
        "    ])\n",
        "\n",
        "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    history = model.fit(X, y_categorical, epochs=epochs, batch_size=32, validation_split=0.2)\n",
        "    return model\n",
        "\n",
        "# 訓練データの読み込み\n",
        "train_zip_path = '/content/drive/My Drive/Colab Notebooks/【練習問題】モノクロ顔画像の感情分類/train.zip'\n",
        "\n",
        "\n",
        "# userid モデルのデータの読み込みとモデルの訓練\n",
        "print('userid_training: (1/4)')\n",
        "X_userid, y_userid = load_data('userid')\n",
        "num_classes_userid = len(np.unique(y_userid))\n",
        "model_userid = build_and_train_model(X_userid, y_userid, num_classes_userid, 7)\n",
        "\n",
        "# pose モデルのデータの読み込みとモデルの訓練\n",
        "print('pose_training: (2/4)')\n",
        "X_pose, y_pose = load_data('pose')\n",
        "num_classes_pose = len(np.unique(y_pose))\n",
        "model_pose = build_and_train_model(X_pose, y_pose, num_classes_pose, 10)\n",
        "\n",
        "# eyes モデルのデータの読み込みとモデルの訓練\n",
        "print('eyes_training: (3/4)')\n",
        "X_eyes, y_eyes = load_data('eyes')\n",
        "num_classes_eyes = len(np.unique(y_eyes))\n",
        "model_eyes = build_and_train_model(X_eyes, y_eyes, num_classes_eyes, 11)\n",
        "\n",
        "# expression モデルのデータの読み込みとモデルの訓練\n",
        "print('expression_training: (4/4)')\n",
        "X_expression, y_expression = load_data('expression')\n",
        "num_classes_expression = len(np.unique(y_expression))\n",
        "model_expression = build_and_train_model(X_expression, y_expression, num_classes_expression, 63)\n",
        "\n",
        "\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "\n",
        "# ベースモデルの予測を取得\n",
        "def get_base_model_predictions(model, X):\n",
        "    return model.predict(X)\n",
        "\n",
        "# ベースモデルの予測を統合\n",
        "X_userid_preds = get_base_model_predictions(model_userid, X_userid)\n",
        "X_pose_preds = get_base_model_predictions(model_pose, X_pose)\n",
        "X_eyes_preds = get_base_model_predictions(model_eyes, X_eyes)\n",
        "X_expression_preds = get_base_model_predictions(model_expression, X_expression)\n",
        "\n",
        "# ベースモデルの予測を統合\n",
        "X_meta = np.hstack([X_userid_preds, X_pose_preds, X_eyes_preds, X_expression_preds])\n",
        "\n",
        "# train_masterからexpression列を取り出す\n",
        "expression = train_master['expression'].values\n",
        "\n",
        "# メタモデルの訓練\n",
        "print('meta_training:')\n",
        "X_train_meta, X_test_meta, y_train_meta, y_test_meta = train_test_split(X_meta, expression, test_size=0.2, random_state=42)\n",
        "meta_model = GradientBoostingClassifier(\n",
        "    n_estimators=200,\n",
        "    learning_rate=0.1,\n",
        "    max_depth=20,\n",
        "    min_samples_split=2,\n",
        "    min_samples_leaf=1,\n",
        "    random_state=42\n",
        ")\n",
        "meta_model.fit(X_train_meta, y_train_meta)\n",
        "\n",
        "# メタモデルの評価\n",
        "accuracy = meta_model.score(X_test_meta, y_test_meta)\n",
        "print(f\"Meta Model Accuracy: {accuracy}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 718
        },
        "id": "47PkczBs04FI",
        "outputId": "5f50e169-c8f0-4998-b18d-34f1526fbbca"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "userid_training: (1/4)\n",
            "Epoch 1/7\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 377ms/step - accuracy: 0.0565 - loss: 2.9985 - val_accuracy: 0.0317 - val_loss: 2.9543\n",
            "Epoch 2/7\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 334ms/step - accuracy: 0.0589 - loss: 2.9364 - val_accuracy: 0.0476 - val_loss: 2.9196\n",
            "Epoch 3/7\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 627ms/step - accuracy: 0.0937 - loss: 2.8776 - val_accuracy: 0.0635 - val_loss: 2.8779\n",
            "Epoch 4/7\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 363ms/step - accuracy: 0.2940 - loss: 2.8255 - val_accuracy: 0.2698 - val_loss: 2.8317\n",
            "Epoch 5/7\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 357ms/step - accuracy: 0.3840 - loss: 2.7636 - val_accuracy: 0.2540 - val_loss: 2.7826\n",
            "Epoch 6/7\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 634ms/step - accuracy: 0.4021 - loss: 2.7161 - val_accuracy: 0.3333 - val_loss: 2.7374\n",
            "Epoch 7/7\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 309ms/step - accuracy: 0.5108 - loss: 2.6493 - val_accuracy: 0.3810 - val_loss: 2.6937\n",
            "pose_training: (2/4)\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-29b9898a7e1b>\u001b[0m in \u001b[0;36m<cell line: 104>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0mX_pose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pose'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[0mnum_classes_pose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m \u001b[0mmodel_pose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_and_train_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_pose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_classes_pose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[0;31m# eyes モデルのデータの読み込みとモデルの訓練\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-11-29b9898a7e1b>\u001b[0m in \u001b[0;36mbuild_and_train_model\u001b[0;34m(X, y, num_classes, epochs)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0;31m# モデルの訓練\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m     \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_categorical\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    316\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mepoch_iterator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menumerate_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 318\u001b[0;31m                     \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    319\u001b[0m                     \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pythonify_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    831\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 833\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    834\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    917\u001b[0m           )\n\u001b[1;32m    918\u001b[0m       )\n\u001b[0;32m--> 919\u001b[0;31m       return self._concrete_variable_creation_fn._call_flat(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    920\u001b[0m           \u001b[0mfiltered_flat_args\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    921\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_concrete_variable_creation_fn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1320\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1321\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1323\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1324\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;34m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m     \u001b[0mflat_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_recording\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bound_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m             outputs = self._bound_context.call_function(\n\u001b[0m\u001b[1;32m    252\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1550\u001b[0m     \u001b[0mcancellation_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcancellation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcancellation_context\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1552\u001b[0;31m       outputs = execute.execute(\n\u001b[0m\u001b[1;32m   1553\u001b[0m           \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1554\u001b[0m           \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     54\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# fine-tuning\n",
        "import zipfile\n",
        "from PIL import Image\n",
        "from io import BytesIO\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# データの読み込み\n",
        "def load_data(label_col):\n",
        "    with zipfile.ZipFile(train_zip_path, 'r') as z:\n",
        "        image_files = z.namelist()\n",
        "        images = []\n",
        "        labels = []\n",
        "\n",
        "        for index, row in train_master.iterrows():\n",
        "            file_name = 'train/' + row['id']\n",
        "            if file_name in image_files:\n",
        "                with z.open(file_name) as img_file:\n",
        "                    img = Image.open(BytesIO(img_file.read()))\n",
        "                    img = img.resize((128, 120))\n",
        "                    img = np.array(img)\n",
        "                    images.append(img)\n",
        "                    labels.append(row[label_col])\n",
        "\n",
        "    X = np.array(images)\n",
        "    y = np.array(labels)\n",
        "    X = X / 255.0\n",
        "    return X, y\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "def build_and_train_model(X, y, num_classes, epochs):\n",
        "    y_categorical = to_categorical(y, num_classes=num_classes)\n",
        "\n",
        "    # モデルの構築\n",
        "    model = Sequential([\n",
        "        Conv2D(32, (3, 3), activation='relu', input_shape=(128, 120, 1)),\n",
        "        MaxPooling2D((2, 2)),\n",
        "        Conv2D(64, (3, 3), activation='relu'),\n",
        "        MaxPooling2D((2, 2)),\n",
        "        Conv2D(128, (3, 3), activation='relu'),\n",
        "        MaxPooling2D((2, 2)),\n",
        "        Flatten(),\n",
        "        Dense(128, activation='relu'),\n",
        "        Dense(num_classes, activation='softmax')\n",
        "    ])\n",
        "\n",
        "    # 最初のいくつかの層を固定（ファインチューニングしない）\n",
        "    for layer in model.layers[:-2]:  # 最後の2層以外を固定\n",
        "        layer.trainable = False\n",
        "\n",
        "    # モデルのコンパイル (ファインチューニング用に学習率を低めに設定)\n",
        "    model.compile(optimizer=Adam(learning_rate=1e-4),\n",
        "                  loss='categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    # モデルの訓練\n",
        "    history = model.fit(X, y_categorical, epochs=epochs, batch_size=32, validation_split=0.2)\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "# 訓練データの読み込み\n",
        "train_zip_path = '/content/drive/My Drive/Colab Notebooks/【練習問題】モノクロ顔画像の感情分類/train.zip'\n",
        "\n",
        "\n",
        "# userid モデルのデータの読み込みとモデルの訓練\n",
        "print('userid_training: (1/4)')\n",
        "X_userid, y_userid = load_data('userid')\n",
        "num_classes_userid = len(np.unique(y_userid))\n",
        "model_userid = build_and_train_model(X_userid, y_userid, num_classes_userid, 50)\n",
        "\n",
        "# pose モデルのデータの読み込みとモデルの訓練\n",
        "print('pose_training: (2/4)')\n",
        "X_pose, y_pose = load_data('pose')\n",
        "num_classes_pose = len(np.unique(y_pose))\n",
        "model_pose = build_and_train_model(X_pose, y_pose, num_classes_pose, 80)\n",
        "\n",
        "# eyes モデルのデータの読み込みとモデルの訓練\n",
        "print('eyes_training: (3/4)')\n",
        "X_eyes, y_eyes = load_data('eyes')\n",
        "num_classes_eyes = len(np.unique(y_eyes))\n",
        "model_eyes = build_and_train_model(X_eyes, y_eyes, num_classes_eyes, 80)\n",
        "\n",
        "# expression モデルのデータの読み込みとモデルの訓練\n",
        "print('expression_training: (4/4)')\n",
        "X_expression, y_expression = load_data('expression')\n",
        "num_classes_expression = len(np.unique(y_expression))\n",
        "model_expression = build_and_train_model(X_expression, y_expression, num_classes_expression, 300)\n",
        "\n",
        "\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "\n",
        "# ベースモデルの予測を取得\n",
        "def get_base_model_predictions(model, X):\n",
        "    return model.predict(X)\n",
        "\n",
        "# ベースモデルの予測を統合\n",
        "X_userid_preds = get_base_model_predictions(model_userid, X_userid)\n",
        "X_pose_preds = get_base_model_predictions(model_pose, X_pose)\n",
        "X_eyes_preds = get_base_model_predictions(model_eyes, X_eyes)\n",
        "X_expression_preds = get_base_model_predictions(model_expression, X_expression)\n",
        "\n",
        "# ベースモデルの予測を統合\n",
        "X_meta = np.hstack([X_userid_preds, X_pose_preds, X_eyes_preds, X_expression_preds])\n",
        "\n",
        "# train_masterからexpression列を取り出す\n",
        "expression = train_master['expression'].values\n",
        "\n",
        "# メタモデルの訓練\n",
        "print('meta_training:')\n",
        "X_train_meta, X_test_meta, y_train_meta, y_test_meta = train_test_split(X_meta, expression, test_size=0.2, random_state=42)\n",
        "meta_model = GradientBoostingClassifier(\n",
        "    n_estimators=200,\n",
        "    learning_rate=0.1,\n",
        "    max_depth=20,\n",
        "    min_samples_split=2,\n",
        "    min_samples_leaf=1,\n",
        "    random_state=42\n",
        ")\n",
        "meta_model.fit(X_train_meta, y_train_meta)\n",
        "\n",
        "# メタモデルの評価\n",
        "accuracy = meta_model.score(X_test_meta, y_test_meta)\n",
        "print(f\"Meta Model Accuracy: {accuracy}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zxe1r1BPq8cP",
        "outputId": "92ebb913-834c-4284-8dc3-0839d0805e5d"
      },
      "execution_count": 14,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "userid_training: (1/4)\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 403ms/step - accuracy: 0.0346 - loss: 2.9919 - val_accuracy: 0.1111 - val_loss: 2.9435\n",
            "Epoch 2/50\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 338ms/step - accuracy: 0.2311 - loss: 2.8996 - val_accuracy: 0.1746 - val_loss: 2.8902\n",
            "Epoch 3/50\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 570ms/step - accuracy: 0.3096 - loss: 2.8157 - val_accuracy: 0.2063 - val_loss: 2.8375\n",
            "Epoch 4/50\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 442ms/step - accuracy: 0.3984 - loss: 2.7345 - val_accuracy: 0.2222 - val_loss: 2.7774\n",
            "Epoch 5/50\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 315ms/step - accuracy: 0.4088 - loss: 2.6711 - val_accuracy: 0.3016 - val_loss: 2.7214\n",
            "Epoch 6/50\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 338ms/step - accuracy: 0.5020 - loss: 2.5970 - val_accuracy: 0.3810 - val_loss: 2.6579\n",
            "Epoch 7/50\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 380ms/step - accuracy: 0.5451 - loss: 2.5101 - val_accuracy: 0.4444 - val_loss: 2.5989\n",
            "Epoch 8/50\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 367ms/step - accuracy: 0.5687 - loss: 2.4799 - val_accuracy: 0.4286 - val_loss: 2.5335\n",
            "Epoch 9/50\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 320ms/step - accuracy: 0.6201 - loss: 2.3744 - val_accuracy: 0.4603 - val_loss: 2.4790\n",
            "Epoch 10/50\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 339ms/step - accuracy: 0.6178 - loss: 2.3108 - val_accuracy: 0.4444 - val_loss: 2.4215\n",
            "Epoch 11/50\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 467ms/step - accuracy: 0.6500 - loss: 2.2343 - val_accuracy: 0.5397 - val_loss: 2.3618\n",
            "Epoch 12/50\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 337ms/step - accuracy: 0.6873 - loss: 2.1904 - val_accuracy: 0.5556 - val_loss: 2.3014\n",
            "Epoch 13/50\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 336ms/step - accuracy: 0.6823 - loss: 2.1279 - val_accuracy: 0.5714 - val_loss: 2.2481\n",
            "Epoch 14/50\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 489ms/step - accuracy: 0.7136 - loss: 2.0728 - val_accuracy: 0.5873 - val_loss: 2.1986\n",
            "Epoch 15/50\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 345ms/step - accuracy: 0.7401 - loss: 1.9939 - val_accuracy: 0.6190 - val_loss: 2.1464\n",
            "Epoch 16/50\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 339ms/step - accuracy: 0.7558 - loss: 1.9176 - val_accuracy: 0.6349 - val_loss: 2.0857\n",
            "Epoch 17/50\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 365ms/step - accuracy: 0.7878 - loss: 1.8893 - val_accuracy: 0.7302 - val_loss: 2.0339\n",
            "Epoch 18/50\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 348ms/step - accuracy: 0.8573 - loss: 1.8105 - val_accuracy: 0.7460 - val_loss: 1.9862\n",
            "Epoch 19/50\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 361ms/step - accuracy: 0.8489 - loss: 1.7441 - val_accuracy: 0.7778 - val_loss: 1.9347\n",
            "Epoch 20/50\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 343ms/step - accuracy: 0.8312 - loss: 1.7073 - val_accuracy: 0.7778 - val_loss: 1.8844\n",
            "Epoch 21/50\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 551ms/step - accuracy: 0.9141 - loss: 1.6227 - val_accuracy: 0.8413 - val_loss: 1.8299\n",
            "Epoch 22/50\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 423ms/step - accuracy: 0.9030 - loss: 1.6000 - val_accuracy: 0.8413 - val_loss: 1.7805\n",
            "Epoch 23/50\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 319ms/step - accuracy: 0.9124 - loss: 1.5415 - val_accuracy: 0.8413 - val_loss: 1.7316\n",
            "Epoch 24/50\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 323ms/step - accuracy: 0.9187 - loss: 1.4578 - val_accuracy: 0.8254 - val_loss: 1.6837\n",
            "Epoch 25/50\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 503ms/step - accuracy: 0.9240 - loss: 1.4464 - val_accuracy: 0.8730 - val_loss: 1.6424\n",
            "Epoch 26/50\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 503ms/step - accuracy: 0.9363 - loss: 1.4023 - val_accuracy: 0.8730 - val_loss: 1.5969\n",
            "Epoch 27/50\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 340ms/step - accuracy: 0.9056 - loss: 1.3674 - val_accuracy: 0.8571 - val_loss: 1.5473\n",
            "Epoch 28/50\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 337ms/step - accuracy: 0.9336 - loss: 1.3064 - val_accuracy: 0.8889 - val_loss: 1.5074\n",
            "Epoch 29/50\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 338ms/step - accuracy: 0.9090 - loss: 1.2830 - val_accuracy: 0.8730 - val_loss: 1.4593\n",
            "Epoch 30/50\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 380ms/step - accuracy: 0.9242 - loss: 1.2174 - val_accuracy: 0.9206 - val_loss: 1.4198\n",
            "Epoch 31/50\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 331ms/step - accuracy: 0.9357 - loss: 1.1651 - val_accuracy: 0.8730 - val_loss: 1.3824\n",
            "Epoch 32/50\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 331ms/step - accuracy: 0.9410 - loss: 1.1016 - val_accuracy: 0.9365 - val_loss: 1.3429\n",
            "Epoch 33/50\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 369ms/step - accuracy: 0.9401 - loss: 1.0904 - val_accuracy: 0.9365 - val_loss: 1.2974\n",
            "Epoch 34/50\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 445ms/step - accuracy: 0.9625 - loss: 1.0387 - val_accuracy: 0.9206 - val_loss: 1.2641\n",
            "Epoch 35/50\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 339ms/step - accuracy: 0.9606 - loss: 0.9864 - val_accuracy: 0.9365 - val_loss: 1.2230\n",
            "Epoch 36/50\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 316ms/step - accuracy: 0.9562 - loss: 0.9952 - val_accuracy: 0.9524 - val_loss: 1.1858\n",
            "Epoch 37/50\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 518ms/step - accuracy: 0.9566 - loss: 0.9542 - val_accuracy: 0.9524 - val_loss: 1.1590\n",
            "Epoch 38/50\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 347ms/step - accuracy: 0.9727 - loss: 0.8812 - val_accuracy: 0.9365 - val_loss: 1.1262\n",
            "Epoch 39/50\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 368ms/step - accuracy: 0.9743 - loss: 0.8772 - val_accuracy: 0.9524 - val_loss: 1.0949\n",
            "Epoch 40/50\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 338ms/step - accuracy: 0.9678 - loss: 0.8568 - val_accuracy: 0.9524 - val_loss: 1.0683\n",
            "Epoch 41/50\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 526ms/step - accuracy: 0.9726 - loss: 0.8181 - val_accuracy: 0.9524 - val_loss: 1.0345\n",
            "Epoch 42/50\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 334ms/step - accuracy: 0.9659 - loss: 0.7945 - val_accuracy: 0.9524 - val_loss: 1.0005\n",
            "Epoch 43/50\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 362ms/step - accuracy: 0.9675 - loss: 0.7580 - val_accuracy: 0.9524 - val_loss: 0.9718\n",
            "Epoch 44/50\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 363ms/step - accuracy: 0.9816 - loss: 0.7133 - val_accuracy: 0.9524 - val_loss: 0.9469\n",
            "Epoch 45/50\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 314ms/step - accuracy: 0.9735 - loss: 0.7063 - val_accuracy: 0.9524 - val_loss: 0.9235\n",
            "Epoch 46/50\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 309ms/step - accuracy: 0.9790 - loss: 0.7004 - val_accuracy: 0.9524 - val_loss: 0.8970\n",
            "Epoch 47/50\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 343ms/step - accuracy: 0.9752 - loss: 0.6445 - val_accuracy: 0.9524 - val_loss: 0.8731\n",
            "Epoch 48/50\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 443ms/step - accuracy: 0.9812 - loss: 0.6101 - val_accuracy: 0.9524 - val_loss: 0.8470\n",
            "Epoch 49/50\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 499ms/step - accuracy: 0.9824 - loss: 0.6366 - val_accuracy: 0.9524 - val_loss: 0.8291\n",
            "Epoch 50/50\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 305ms/step - accuracy: 0.9901 - loss: 0.6098 - val_accuracy: 0.9524 - val_loss: 0.8029\n",
            "pose_training: (2/4)\n",
            "Epoch 1/80\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 355ms/step - accuracy: 0.3797 - loss: 1.3736 - val_accuracy: 0.5873 - val_loss: 1.3285\n",
            "Epoch 2/80\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 448ms/step - accuracy: 0.6345 - loss: 1.3007 - val_accuracy: 0.6032 - val_loss: 1.2674\n",
            "Epoch 3/80\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 608ms/step - accuracy: 0.6172 - loss: 1.2220 - val_accuracy: 0.6190 - val_loss: 1.2203\n",
            "Epoch 4/80\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 341ms/step - accuracy: 0.7238 - loss: 1.1566 - val_accuracy: 0.6190 - val_loss: 1.1613\n",
            "Epoch 5/80\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 308ms/step - accuracy: 0.6622 - loss: 1.0936 - val_accuracy: 0.6349 - val_loss: 1.1218\n",
            "Epoch 6/80\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 424ms/step - accuracy: 0.7111 - loss: 1.0546 - val_accuracy: 0.6508 - val_loss: 1.0775\n",
            "Epoch 7/80\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 329ms/step - accuracy: 0.7794 - loss: 1.0088 - val_accuracy: 0.6508 - val_loss: 1.0554\n",
            "Epoch 8/80\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 334ms/step - accuracy: 0.6967 - loss: 0.9960 - val_accuracy: 0.6349 - val_loss: 1.0047\n",
            "Epoch 9/80\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 342ms/step - accuracy: 0.7527 - loss: 0.9337 - val_accuracy: 0.6825 - val_loss: 0.9874\n",
            "Epoch 10/80\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 616ms/step - accuracy: 0.7351 - loss: 0.9142 - val_accuracy: 0.6825 - val_loss: 0.9562\n",
            "Epoch 11/80\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 342ms/step - accuracy: 0.7614 - loss: 0.8831 - val_accuracy: 0.6667 - val_loss: 0.9211\n",
            "Epoch 12/80\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 359ms/step - accuracy: 0.7778 - loss: 0.8334 - val_accuracy: 0.6984 - val_loss: 0.9089\n",
            "Epoch 13/80\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 332ms/step - accuracy: 0.8174 - loss: 0.8009 - val_accuracy: 0.6667 - val_loss: 0.8764\n",
            "Epoch 14/80\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 521ms/step - accuracy: 0.7844 - loss: 0.8102 - val_accuracy: 0.6825 - val_loss: 0.8626\n",
            "Epoch 15/80\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 513ms/step - accuracy: 0.7950 - loss: 0.7657 - val_accuracy: 0.7143 - val_loss: 0.8405\n",
            "Epoch 16/80\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 348ms/step - accuracy: 0.8311 - loss: 0.7351 - val_accuracy: 0.7302 - val_loss: 0.8238\n",
            "Epoch 17/80\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 335ms/step - accuracy: 0.8276 - loss: 0.6844 - val_accuracy: 0.6825 - val_loss: 0.7968\n",
            "Epoch 18/80\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 497ms/step - accuracy: 0.7974 - loss: 0.7219 - val_accuracy: 0.7460 - val_loss: 0.7981\n",
            "Epoch 19/80\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 349ms/step - accuracy: 0.8282 - loss: 0.6916 - val_accuracy: 0.7619 - val_loss: 0.7614\n",
            "Epoch 20/80\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 340ms/step - accuracy: 0.8793 - loss: 0.6441 - val_accuracy: 0.7460 - val_loss: 0.7479\n",
            "Epoch 21/80\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 527ms/step - accuracy: 0.8325 - loss: 0.6440 - val_accuracy: 0.7460 - val_loss: 0.7408\n",
            "Epoch 22/80\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 335ms/step - accuracy: 0.8728 - loss: 0.6246 - val_accuracy: 0.7619 - val_loss: 0.7255\n",
            "Epoch 23/80\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 373ms/step - accuracy: 0.8735 - loss: 0.6115 - val_accuracy: 0.7778 - val_loss: 0.7130\n",
            "Epoch 24/80\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 484ms/step - accuracy: 0.8698 - loss: 0.5722 - val_accuracy: 0.7937 - val_loss: 0.6957\n",
            "Epoch 25/80\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 463ms/step - accuracy: 0.8763 - loss: 0.5856 - val_accuracy: 0.8095 - val_loss: 0.6874\n",
            "Epoch 26/80\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 328ms/step - accuracy: 0.8789 - loss: 0.5686 - val_accuracy: 0.7937 - val_loss: 0.6748\n",
            "Epoch 27/80\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 372ms/step - accuracy: 0.8845 - loss: 0.5506 - val_accuracy: 0.8095 - val_loss: 0.6522\n",
            "Epoch 28/80\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 344ms/step - accuracy: 0.9077 - loss: 0.5267 - val_accuracy: 0.8413 - val_loss: 0.6556\n",
            "Epoch 29/80\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 318ms/step - accuracy: 0.9064 - loss: 0.5048 - val_accuracy: 0.8254 - val_loss: 0.6368\n",
            "Epoch 30/80\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 322ms/step - accuracy: 0.8598 - loss: 0.5510 - val_accuracy: 0.8254 - val_loss: 0.6210\n",
            "Epoch 31/80\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 368ms/step - accuracy: 0.8591 - loss: 0.5224 - val_accuracy: 0.8254 - val_loss: 0.6169\n",
            "Epoch 32/80\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 413ms/step - accuracy: 0.8867 - loss: 0.5204 - val_accuracy: 0.8571 - val_loss: 0.6102\n",
            "Epoch 33/80\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 330ms/step - accuracy: 0.9039 - loss: 0.4778 - val_accuracy: 0.8730 - val_loss: 0.5982\n",
            "Epoch 34/80\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 344ms/step - accuracy: 0.8946 - loss: 0.4623 - val_accuracy: 0.8571 - val_loss: 0.5843\n",
            "Epoch 35/80\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 456ms/step - accuracy: 0.9121 - loss: 0.4417 - val_accuracy: 0.8571 - val_loss: 0.5767\n",
            "Epoch 36/80\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 355ms/step - accuracy: 0.9008 - loss: 0.4563 - val_accuracy: 0.8571 - val_loss: 0.5672\n",
            "Epoch 37/80\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 309ms/step - accuracy: 0.9181 - loss: 0.4510 - val_accuracy: 0.8571 - val_loss: 0.5589\n",
            "Epoch 38/80\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 335ms/step - accuracy: 0.9403 - loss: 0.4034 - val_accuracy: 0.8730 - val_loss: 0.5531\n",
            "Epoch 39/80\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 326ms/step - accuracy: 0.9363 - loss: 0.3849 - val_accuracy: 0.8730 - val_loss: 0.5409\n",
            "Epoch 40/80\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 318ms/step - accuracy: 0.9189 - loss: 0.4123 - val_accuracy: 0.8889 - val_loss: 0.5334\n",
            "Epoch 41/80\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 340ms/step - accuracy: 0.9294 - loss: 0.4019 - val_accuracy: 0.8571 - val_loss: 0.5234\n",
            "Epoch 42/80\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 606ms/step - accuracy: 0.9332 - loss: 0.4001 - val_accuracy: 0.8889 - val_loss: 0.5235\n",
            "Epoch 43/80\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 349ms/step - accuracy: 0.9384 - loss: 0.3805 - val_accuracy: 0.8730 - val_loss: 0.5078\n",
            "Epoch 44/80\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 338ms/step - accuracy: 0.9482 - loss: 0.3897 - val_accuracy: 0.8889 - val_loss: 0.5005\n",
            "Epoch 45/80\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 383ms/step - accuracy: 0.9403 - loss: 0.3763 - val_accuracy: 0.8730 - val_loss: 0.4916\n",
            "Epoch 46/80\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 321ms/step - accuracy: 0.9568 - loss: 0.3662 - val_accuracy: 0.8889 - val_loss: 0.4928\n",
            "Epoch 47/80\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 323ms/step - accuracy: 0.9539 - loss: 0.3528 - val_accuracy: 0.8730 - val_loss: 0.4806\n",
            "Epoch 48/80\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 322ms/step - accuracy: 0.9643 - loss: 0.3368 - val_accuracy: 0.8889 - val_loss: 0.4695\n",
            "Epoch 49/80\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 387ms/step - accuracy: 0.9720 - loss: 0.3268 - val_accuracy: 0.8889 - val_loss: 0.4669\n",
            "Epoch 50/80\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 307ms/step - accuracy: 0.9535 - loss: 0.3329 - val_accuracy: 0.8889 - val_loss: 0.4636\n",
            "Epoch 51/80\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 336ms/step - accuracy: 0.9564 - loss: 0.3274 - val_accuracy: 0.9048 - val_loss: 0.4517\n",
            "Epoch 52/80\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 345ms/step - accuracy: 0.9635 - loss: 0.3220 - val_accuracy: 0.8889 - val_loss: 0.4475\n",
            "Epoch 53/80\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 601ms/step - accuracy: 0.9704 - loss: 0.3083 - val_accuracy: 0.9048 - val_loss: 0.4402\n",
            "Epoch 54/80\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 330ms/step - accuracy: 0.9521 - loss: 0.3181 - val_accuracy: 0.8889 - val_loss: 0.4402\n",
            "Epoch 55/80\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 344ms/step - accuracy: 0.9688 - loss: 0.2980 - val_accuracy: 0.9048 - val_loss: 0.4284\n",
            "Epoch 56/80\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 341ms/step - accuracy: 0.9751 - loss: 0.2877 - val_accuracy: 0.9048 - val_loss: 0.4262\n",
            "Epoch 57/80\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 323ms/step - accuracy: 0.9562 - loss: 0.3053 - val_accuracy: 0.9048 - val_loss: 0.4170\n",
            "Epoch 58/80\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 371ms/step - accuracy: 0.9747 - loss: 0.2681 - val_accuracy: 0.9048 - val_loss: 0.4125\n",
            "Epoch 59/80\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 334ms/step - accuracy: 0.9813 - loss: 0.2494 - val_accuracy: 0.9048 - val_loss: 0.4101\n",
            "Epoch 60/80\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 644ms/step - accuracy: 0.9591 - loss: 0.2870 - val_accuracy: 0.8889 - val_loss: 0.4043\n",
            "Epoch 61/80\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 365ms/step - accuracy: 0.9691 - loss: 0.2668 - val_accuracy: 0.9048 - val_loss: 0.3931\n",
            "Epoch 62/80\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 344ms/step - accuracy: 0.9643 - loss: 0.2940 - val_accuracy: 0.9048 - val_loss: 0.3952\n",
            "Epoch 63/80\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 634ms/step - accuracy: 0.9429 - loss: 0.2825 - val_accuracy: 0.9048 - val_loss: 0.3890\n",
            "Epoch 64/80\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 335ms/step - accuracy: 0.9653 - loss: 0.2667 - val_accuracy: 0.9206 - val_loss: 0.3774\n",
            "Epoch 65/80\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 315ms/step - accuracy: 0.9637 - loss: 0.2587 - val_accuracy: 0.9048 - val_loss: 0.3885\n",
            "Epoch 66/80\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 328ms/step - accuracy: 0.9814 - loss: 0.2294 - val_accuracy: 0.9206 - val_loss: 0.3708\n",
            "Epoch 67/80\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 614ms/step - accuracy: 0.9646 - loss: 0.2475 - val_accuracy: 0.8889 - val_loss: 0.3722\n",
            "Epoch 68/80\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 322ms/step - accuracy: 0.9639 - loss: 0.2298 - val_accuracy: 0.9206 - val_loss: 0.3629\n",
            "Epoch 69/80\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 337ms/step - accuracy: 0.9770 - loss: 0.2233 - val_accuracy: 0.9048 - val_loss: 0.3646\n",
            "Epoch 70/80\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 353ms/step - accuracy: 0.9645 - loss: 0.2351 - val_accuracy: 0.9048 - val_loss: 0.3581\n",
            "Epoch 71/80\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 596ms/step - accuracy: 0.9680 - loss: 0.2256 - val_accuracy: 0.9365 - val_loss: 0.3475\n",
            "Epoch 72/80\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 336ms/step - accuracy: 0.9761 - loss: 0.2172 - val_accuracy: 0.9048 - val_loss: 0.3516\n",
            "Epoch 73/80\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 329ms/step - accuracy: 0.9729 - loss: 0.2132 - val_accuracy: 0.9048 - val_loss: 0.3455\n",
            "Epoch 74/80\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 339ms/step - accuracy: 0.9766 - loss: 0.1938 - val_accuracy: 0.9048 - val_loss: 0.3436\n",
            "Epoch 75/80\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 484ms/step - accuracy: 0.9834 - loss: 0.1835 - val_accuracy: 0.9048 - val_loss: 0.3379\n",
            "Epoch 76/80\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 315ms/step - accuracy: 0.9698 - loss: 0.1981 - val_accuracy: 0.9048 - val_loss: 0.3313\n",
            "Epoch 77/80\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 372ms/step - accuracy: 0.9817 - loss: 0.2086 - val_accuracy: 0.9206 - val_loss: 0.3248\n",
            "Epoch 78/80\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 358ms/step - accuracy: 0.9830 - loss: 0.1987 - val_accuracy: 0.9206 - val_loss: 0.3325\n",
            "Epoch 79/80\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 326ms/step - accuracy: 0.9767 - loss: 0.1991 - val_accuracy: 0.9365 - val_loss: 0.3179\n",
            "Epoch 80/80\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 334ms/step - accuracy: 0.9850 - loss: 0.1818 - val_accuracy: 0.9524 - val_loss: 0.3263\n",
            "eyes_training: (3/4)\n",
            "Epoch 1/80\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 369ms/step - accuracy: 0.4255 - loss: 0.7037 - val_accuracy: 0.4603 - val_loss: 0.6931\n",
            "Epoch 2/80\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 457ms/step - accuracy: 0.6132 - loss: 0.6808 - val_accuracy: 0.5238 - val_loss: 0.6885\n",
            "Epoch 3/80\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 323ms/step - accuracy: 0.5328 - loss: 0.6657 - val_accuracy: 0.6825 - val_loss: 0.6806\n",
            "Epoch 4/80\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 331ms/step - accuracy: 0.6793 - loss: 0.6619 - val_accuracy: 0.5238 - val_loss: 0.6781\n",
            "Epoch 5/80\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 340ms/step - accuracy: 0.7861 - loss: 0.6388 - val_accuracy: 0.5873 - val_loss: 0.6744\n",
            "Epoch 6/80\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 347ms/step - accuracy: 0.6560 - loss: 0.6293 - val_accuracy: 0.6667 - val_loss: 0.6670\n",
            "Epoch 7/80\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 322ms/step - accuracy: 0.7725 - loss: 0.6256 - val_accuracy: 0.6667 - val_loss: 0.6615\n",
            "Epoch 8/80\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 341ms/step - accuracy: 0.7929 - loss: 0.6174 - val_accuracy: 0.6349 - val_loss: 0.6570\n",
            "Epoch 9/80\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 598ms/step - accuracy: 0.8107 - loss: 0.5949 - val_accuracy: 0.6667 - val_loss: 0.6509\n",
            "Epoch 10/80\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 356ms/step - accuracy: 0.8244 - loss: 0.5953 - val_accuracy: 0.6667 - val_loss: 0.6446\n",
            "Epoch 11/80\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 336ms/step - accuracy: 0.8150 - loss: 0.5904 - val_accuracy: 0.6190 - val_loss: 0.6379\n",
            "Epoch 12/80\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 510ms/step - accuracy: 0.8537 - loss: 0.5735 - val_accuracy: 0.6984 - val_loss: 0.6347\n",
            "Epoch 13/80\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 468ms/step - accuracy: 0.8607 - loss: 0.5625 - val_accuracy: 0.6508 - val_loss: 0.6276\n",
            "Epoch 14/80\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 325ms/step - accuracy: 0.8707 - loss: 0.5423 - val_accuracy: 0.6508 - val_loss: 0.6216\n",
            "Epoch 15/80\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 322ms/step - accuracy: 0.9022 - loss: 0.5339 - val_accuracy: 0.7302 - val_loss: 0.6192\n",
            "Epoch 16/80\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 465ms/step - accuracy: 0.8759 - loss: 0.5226 - val_accuracy: 0.6984 - val_loss: 0.6113\n",
            "Epoch 17/80\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 322ms/step - accuracy: 0.8673 - loss: 0.5155 - val_accuracy: 0.6984 - val_loss: 0.6054\n",
            "Epoch 18/80\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 342ms/step - accuracy: 0.9273 - loss: 0.5092 - val_accuracy: 0.7460 - val_loss: 0.6011\n",
            "Epoch 19/80\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 464ms/step - accuracy: 0.8646 - loss: 0.5009 - val_accuracy: 0.6825 - val_loss: 0.5947\n",
            "Epoch 20/80\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 479ms/step - accuracy: 0.9012 - loss: 0.4938 - val_accuracy: 0.6984 - val_loss: 0.5889\n",
            "Epoch 21/80\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 311ms/step - accuracy: 0.8658 - loss: 0.4889 - val_accuracy: 0.7460 - val_loss: 0.5883\n",
            "Epoch 22/80\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 327ms/step - accuracy: 0.9011 - loss: 0.4767 - val_accuracy: 0.7302 - val_loss: 0.5780\n",
            "Epoch 23/80\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 353ms/step - accuracy: 0.9476 - loss: 0.4587 - val_accuracy: 0.7460 - val_loss: 0.5722\n",
            "Epoch 24/80\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 340ms/step - accuracy: 0.9283 - loss: 0.4598 - val_accuracy: 0.7460 - val_loss: 0.5662\n",
            "Epoch 25/80\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 307ms/step - accuracy: 0.9423 - loss: 0.4370 - val_accuracy: 0.7460 - val_loss: 0.5621\n",
            "Epoch 26/80\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 324ms/step - accuracy: 0.9152 - loss: 0.4406 - val_accuracy: 0.7937 - val_loss: 0.5558\n",
            "Epoch 27/80\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 321ms/step - accuracy: 0.9415 - loss: 0.4257 - val_accuracy: 0.7937 - val_loss: 0.5506\n",
            "Epoch 28/80\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 322ms/step - accuracy: 0.9342 - loss: 0.4354 - val_accuracy: 0.7460 - val_loss: 0.5443\n",
            "Epoch 29/80\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 331ms/step - accuracy: 0.9624 - loss: 0.4139 - val_accuracy: 0.7460 - val_loss: 0.5452\n",
            "Epoch 30/80\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 338ms/step - accuracy: 0.9300 - loss: 0.4165 - val_accuracy: 0.7937 - val_loss: 0.5354\n",
            "Epoch 31/80\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 339ms/step - accuracy: 0.9429 - loss: 0.4023 - val_accuracy: 0.7937 - val_loss: 0.5318\n",
            "Epoch 32/80\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 329ms/step - accuracy: 0.9316 - loss: 0.4079 - val_accuracy: 0.7937 - val_loss: 0.5257\n",
            "Epoch 33/80\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 344ms/step - accuracy: 0.9291 - loss: 0.3901 - val_accuracy: 0.7937 - val_loss: 0.5211\n",
            "Epoch 34/80\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 602ms/step - accuracy: 0.9539 - loss: 0.3887 - val_accuracy: 0.7937 - val_loss: 0.5178\n",
            "Epoch 35/80\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 316ms/step - accuracy: 0.9351 - loss: 0.3859 - val_accuracy: 0.7937 - val_loss: 0.5121\n",
            "Epoch 36/80\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 339ms/step - accuracy: 0.9576 - loss: 0.3617 - val_accuracy: 0.7937 - val_loss: 0.5054\n",
            "Epoch 37/80\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 323ms/step - accuracy: 0.9277 - loss: 0.3572 - val_accuracy: 0.7937 - val_loss: 0.5035\n",
            "Epoch 38/80\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 607ms/step - accuracy: 0.9555 - loss: 0.3582 - val_accuracy: 0.7937 - val_loss: 0.4969\n",
            "Epoch 39/80\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 310ms/step - accuracy: 0.9532 - loss: 0.3451 - val_accuracy: 0.7937 - val_loss: 0.4962\n",
            "Epoch 40/80\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 330ms/step - accuracy: 0.9311 - loss: 0.3383 - val_accuracy: 0.7937 - val_loss: 0.4891\n",
            "Epoch 41/80\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 437ms/step - accuracy: 0.9740 - loss: 0.3315 - val_accuracy: 0.8254 - val_loss: 0.4835\n",
            "Epoch 42/80\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 328ms/step - accuracy: 0.9535 - loss: 0.3210 - val_accuracy: 0.7937 - val_loss: 0.4855\n",
            "Epoch 43/80\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 341ms/step - accuracy: 0.9498 - loss: 0.3165 - val_accuracy: 0.8413 - val_loss: 0.4725\n",
            "Epoch 44/80\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 360ms/step - accuracy: 0.9486 - loss: 0.3351 - val_accuracy: 0.7937 - val_loss: 0.4743\n",
            "Epoch 45/80\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 352ms/step - accuracy: 0.9358 - loss: 0.3194 - val_accuracy: 0.7937 - val_loss: 0.4664\n",
            "Epoch 46/80\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 341ms/step - accuracy: 0.9500 - loss: 0.3101 - val_accuracy: 0.7778 - val_loss: 0.4726\n",
            "Epoch 47/80\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 369ms/step - accuracy: 0.9528 - loss: 0.3037 - val_accuracy: 0.8413 - val_loss: 0.4577\n",
            "Epoch 48/80\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 512ms/step - accuracy: 0.9574 - loss: 0.2965 - val_accuracy: 0.7937 - val_loss: 0.4597\n",
            "Epoch 49/80\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 377ms/step - accuracy: 0.9690 - loss: 0.2864 - val_accuracy: 0.7937 - val_loss: 0.4500\n",
            "Epoch 50/80\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 322ms/step - accuracy: 0.9644 - loss: 0.2766 - val_accuracy: 0.7937 - val_loss: 0.4484\n",
            "Epoch 51/80\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 315ms/step - accuracy: 0.9456 - loss: 0.2855 - val_accuracy: 0.7937 - val_loss: 0.4504\n",
            "Epoch 52/80\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 483ms/step - accuracy: 0.9549 - loss: 0.2875 - val_accuracy: 0.8095 - val_loss: 0.4402\n",
            "Epoch 53/80\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 332ms/step - accuracy: 0.9741 - loss: 0.2681 - val_accuracy: 0.7937 - val_loss: 0.4422\n",
            "Epoch 54/80\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 321ms/step - accuracy: 0.9807 - loss: 0.2514 - val_accuracy: 0.8413 - val_loss: 0.4327\n",
            "Epoch 55/80\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 350ms/step - accuracy: 0.9684 - loss: 0.2571 - val_accuracy: 0.8095 - val_loss: 0.4301\n",
            "Epoch 56/80\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 548ms/step - accuracy: 0.9586 - loss: 0.2598 - val_accuracy: 0.8095 - val_loss: 0.4363\n",
            "Epoch 57/80\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 414ms/step - accuracy: 0.9671 - loss: 0.2403 - val_accuracy: 0.8413 - val_loss: 0.4219\n",
            "Epoch 58/80\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 366ms/step - accuracy: 0.9466 - loss: 0.2583 - val_accuracy: 0.8095 - val_loss: 0.4265\n",
            "Epoch 59/80\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 344ms/step - accuracy: 0.9755 - loss: 0.2208 - val_accuracy: 0.8413 - val_loss: 0.4154\n",
            "Epoch 60/80\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 526ms/step - accuracy: 0.9704 - loss: 0.2388 - val_accuracy: 0.8095 - val_loss: 0.4192\n",
            "Epoch 61/80\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 459ms/step - accuracy: 0.9761 - loss: 0.2319 - val_accuracy: 0.8095 - val_loss: 0.4146\n",
            "Epoch 62/80\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 369ms/step - accuracy: 0.9686 - loss: 0.2222 - val_accuracy: 0.8095 - val_loss: 0.4066\n",
            "Epoch 63/80\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 330ms/step - accuracy: 0.9648 - loss: 0.2237 - val_accuracy: 0.8095 - val_loss: 0.4075\n",
            "Epoch 64/80\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 507ms/step - accuracy: 0.9598 - loss: 0.2277 - val_accuracy: 0.8095 - val_loss: 0.4097\n",
            "Epoch 65/80\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 497ms/step - accuracy: 0.9667 - loss: 0.2176 - val_accuracy: 0.8413 - val_loss: 0.3971\n",
            "Epoch 66/80\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 348ms/step - accuracy: 0.9752 - loss: 0.2220 - val_accuracy: 0.8095 - val_loss: 0.4007\n",
            "Epoch 67/80\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 374ms/step - accuracy: 0.9700 - loss: 0.2134 - val_accuracy: 0.8254 - val_loss: 0.3945\n",
            "Epoch 68/80\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 401ms/step - accuracy: 0.9724 - loss: 0.1977 - val_accuracy: 0.8254 - val_loss: 0.3895\n",
            "Epoch 69/80\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 594ms/step - accuracy: 0.9553 - loss: 0.2124 - val_accuracy: 0.8254 - val_loss: 0.3869\n",
            "Epoch 70/80\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 340ms/step - accuracy: 0.9751 - loss: 0.2010 - val_accuracy: 0.8254 - val_loss: 0.3883\n",
            "Epoch 71/80\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 332ms/step - accuracy: 0.9667 - loss: 0.1955 - val_accuracy: 0.8254 - val_loss: 0.3798\n",
            "Epoch 72/80\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 343ms/step - accuracy: 0.9708 - loss: 0.1952 - val_accuracy: 0.8254 - val_loss: 0.3786\n",
            "Epoch 73/80\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 566ms/step - accuracy: 0.9660 - loss: 0.1967 - val_accuracy: 0.8254 - val_loss: 0.3751\n",
            "Epoch 74/80\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 339ms/step - accuracy: 0.9464 - loss: 0.2139 - val_accuracy: 0.8254 - val_loss: 0.3744\n",
            "Epoch 75/80\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 331ms/step - accuracy: 0.9630 - loss: 0.1860 - val_accuracy: 0.8254 - val_loss: 0.3704\n",
            "Epoch 76/80\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 350ms/step - accuracy: 0.9730 - loss: 0.1736 - val_accuracy: 0.8254 - val_loss: 0.3680\n",
            "Epoch 77/80\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 602ms/step - accuracy: 0.9811 - loss: 0.1785 - val_accuracy: 0.8889 - val_loss: 0.3614\n",
            "Epoch 78/80\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 314ms/step - accuracy: 0.9727 - loss: 0.1803 - val_accuracy: 0.8571 - val_loss: 0.3692\n",
            "Epoch 79/80\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 304ms/step - accuracy: 0.9802 - loss: 0.1651 - val_accuracy: 0.8889 - val_loss: 0.3575\n",
            "Epoch 80/80\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 342ms/step - accuracy: 0.9694 - loss: 0.1801 - val_accuracy: 0.8571 - val_loss: 0.3675\n",
            "expression_training: (4/4)\n",
            "Epoch 1/300\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 540ms/step - accuracy: 0.2567 - loss: 1.4020 - val_accuracy: 0.2698 - val_loss: 1.3891\n",
            "Epoch 2/300\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 361ms/step - accuracy: 0.2258 - loss: 1.3819 - val_accuracy: 0.1905 - val_loss: 1.4143\n",
            "Epoch 3/300\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 332ms/step - accuracy: 0.2899 - loss: 1.3697 - val_accuracy: 0.3016 - val_loss: 1.3859\n",
            "Epoch 4/300\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 420ms/step - accuracy: 0.3198 - loss: 1.3657 - val_accuracy: 0.2857 - val_loss: 1.3697\n",
            "Epoch 5/300\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 331ms/step - accuracy: 0.3043 - loss: 1.3695 - val_accuracy: 0.2857 - val_loss: 1.3814\n",
            "Epoch 6/300\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 358ms/step - accuracy: 0.3584 - loss: 1.3532 - val_accuracy: 0.2063 - val_loss: 1.3790\n",
            "Epoch 7/300\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 321ms/step - accuracy: 0.3847 - loss: 1.3428 - val_accuracy: 0.2381 - val_loss: 1.3901\n",
            "Epoch 8/300\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 347ms/step - accuracy: 0.3807 - loss: 1.3512 - val_accuracy: 0.3016 - val_loss: 1.3751\n",
            "Epoch 9/300\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 467ms/step - accuracy: 0.4206 - loss: 1.3373 - val_accuracy: 0.2857 - val_loss: 1.3724\n",
            "Epoch 10/300\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 404ms/step - accuracy: 0.4150 - loss: 1.3387 - val_accuracy: 0.3016 - val_loss: 1.3705\n",
            "Epoch 11/300\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 336ms/step - accuracy: 0.3612 - loss: 1.3320 - val_accuracy: 0.2540 - val_loss: 1.3780\n",
            "Epoch 12/300\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 487ms/step - accuracy: 0.3744 - loss: 1.3247 - val_accuracy: 0.3175 - val_loss: 1.3773\n",
            "Epoch 13/300\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 445ms/step - accuracy: 0.4151 - loss: 1.3174 - val_accuracy: 0.2698 - val_loss: 1.3780\n",
            "Epoch 14/300\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 333ms/step - accuracy: 0.4219 - loss: 1.3118 - val_accuracy: 0.3333 - val_loss: 1.3632\n",
            "Epoch 15/300\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 318ms/step - accuracy: 0.4286 - loss: 1.3105 - val_accuracy: 0.2857 - val_loss: 1.3768\n",
            "Epoch 16/300\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 424ms/step - accuracy: 0.4622 - loss: 1.3167 - val_accuracy: 0.3175 - val_loss: 1.3699\n",
            "Epoch 17/300\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 342ms/step - accuracy: 0.4226 - loss: 1.3186 - val_accuracy: 0.3492 - val_loss: 1.3693\n",
            "Epoch 18/300\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 358ms/step - accuracy: 0.4572 - loss: 1.3042 - val_accuracy: 0.2698 - val_loss: 1.3776\n",
            "Epoch 19/300\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 457ms/step - accuracy: 0.4588 - loss: 1.2968 - val_accuracy: 0.3651 - val_loss: 1.3674\n",
            "Epoch 20/300\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 345ms/step - accuracy: 0.4586 - loss: 1.2979 - val_accuracy: 0.2540 - val_loss: 1.3753\n",
            "Epoch 21/300\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 313ms/step - accuracy: 0.4630 - loss: 1.2924 - val_accuracy: 0.3333 - val_loss: 1.3691\n",
            "Epoch 22/300\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 300ms/step - accuracy: 0.4724 - loss: 1.2861 - val_accuracy: 0.3333 - val_loss: 1.3685\n",
            "Epoch 23/300\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 319ms/step - accuracy: 0.4424 - loss: 1.2810 - val_accuracy: 0.3016 - val_loss: 1.3669\n",
            "Epoch 24/300\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 522ms/step - accuracy: 0.5062 - loss: 1.2771 - val_accuracy: 0.2857 - val_loss: 1.3902\n",
            "Epoch 25/300\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 451ms/step - accuracy: 0.4321 - loss: 1.2983 - val_accuracy: 0.3651 - val_loss: 1.3595\n",
            "Epoch 26/300\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 323ms/step - accuracy: 0.5034 - loss: 1.2719 - val_accuracy: 0.3175 - val_loss: 1.3707\n",
            "Epoch 27/300\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 320ms/step - accuracy: 0.4346 - loss: 1.2774 - val_accuracy: 0.3175 - val_loss: 1.3713\n",
            "Epoch 28/300\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 331ms/step - accuracy: 0.4539 - loss: 1.2806 - val_accuracy: 0.3333 - val_loss: 1.3734\n",
            "Epoch 29/300\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 406ms/step - accuracy: 0.4632 - loss: 1.2609 - val_accuracy: 0.3175 - val_loss: 1.3900\n",
            "Epoch 30/300\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 316ms/step - accuracy: 0.4676 - loss: 1.2619 - val_accuracy: 0.3175 - val_loss: 1.3719\n",
            "Epoch 31/300\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 327ms/step - accuracy: 0.4902 - loss: 1.2515 - val_accuracy: 0.3492 - val_loss: 1.3658\n",
            "Epoch 32/300\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 322ms/step - accuracy: 0.4835 - loss: 1.2619 - val_accuracy: 0.2857 - val_loss: 1.3843\n",
            "Epoch 33/300\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 531ms/step - accuracy: 0.4687 - loss: 1.2507 - val_accuracy: 0.3175 - val_loss: 1.3702\n",
            "Epoch 34/300\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 312ms/step - accuracy: 0.5072 - loss: 1.2480 - val_accuracy: 0.3175 - val_loss: 1.3730\n",
            "Epoch 35/300\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 307ms/step - accuracy: 0.4889 - loss: 1.2534 - val_accuracy: 0.3333 - val_loss: 1.3731\n",
            "Epoch 36/300\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 293ms/step - accuracy: 0.5223 - loss: 1.2432 - val_accuracy: 0.2857 - val_loss: 1.3734\n",
            "Epoch 37/300\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 305ms/step - accuracy: 0.5624 - loss: 1.2019 - val_accuracy: 0.2857 - val_loss: 1.3852\n",
            "Epoch 38/300\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 542ms/step - accuracy: 0.4836 - loss: 1.2479 - val_accuracy: 0.3175 - val_loss: 1.3900\n",
            "Epoch 39/300\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 441ms/step - accuracy: 0.5516 - loss: 1.2186 - val_accuracy: 0.3810 - val_loss: 1.3627\n",
            "Epoch 40/300\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 329ms/step - accuracy: 0.4958 - loss: 1.2142 - val_accuracy: 0.3016 - val_loss: 1.3750\n",
            "Epoch 41/300\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 453ms/step - accuracy: 0.4796 - loss: 1.2154 - val_accuracy: 0.3175 - val_loss: 1.3890\n",
            "Epoch 42/300\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 529ms/step - accuracy: 0.5419 - loss: 1.2128 - val_accuracy: 0.3016 - val_loss: 1.3750\n",
            "Epoch 43/300\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 311ms/step - accuracy: 0.5373 - loss: 1.2032 - val_accuracy: 0.3492 - val_loss: 1.3727\n",
            "Epoch 44/300\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 339ms/step - accuracy: 0.4752 - loss: 1.2277 - val_accuracy: 0.3175 - val_loss: 1.3831\n",
            "Epoch 45/300\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 343ms/step - accuracy: 0.5328 - loss: 1.2168 - val_accuracy: 0.3492 - val_loss: 1.3757\n",
            "Epoch 46/300\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 440ms/step - accuracy: 0.5690 - loss: 1.1902 - val_accuracy: 0.3333 - val_loss: 1.3770\n",
            "Epoch 47/300\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 352ms/step - accuracy: 0.5396 - loss: 1.2069 - val_accuracy: 0.2698 - val_loss: 1.3841\n",
            "Epoch 48/300\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 331ms/step - accuracy: 0.5330 - loss: 1.1961 - val_accuracy: 0.3333 - val_loss: 1.3766\n",
            "Epoch 49/300\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 540ms/step - accuracy: 0.5179 - loss: 1.2161 - val_accuracy: 0.2857 - val_loss: 1.3950\n",
            "Epoch 50/300\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 342ms/step - accuracy: 0.5341 - loss: 1.2065 - val_accuracy: 0.3175 - val_loss: 1.3797\n",
            "Epoch 51/300\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 301ms/step - accuracy: 0.5558 - loss: 1.1789 - val_accuracy: 0.3016 - val_loss: 1.3808\n",
            "Epoch 52/300\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 385ms/step - accuracy: 0.5526 - loss: 1.1743 - val_accuracy: 0.3016 - val_loss: 1.3879\n",
            "Epoch 53/300\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 593ms/step - accuracy: 0.5923 - loss: 1.1736 - val_accuracy: 0.3333 - val_loss: 1.3889\n",
            "Epoch 54/300\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 354ms/step - accuracy: 0.5431 - loss: 1.1757 - val_accuracy: 0.3016 - val_loss: 1.3780\n",
            "Epoch 55/300\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 357ms/step - accuracy: 0.5527 - loss: 1.1646 - val_accuracy: 0.3175 - val_loss: 1.3861\n",
            "Epoch 56/300\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 451ms/step - accuracy: 0.4963 - loss: 1.1832 - val_accuracy: 0.2857 - val_loss: 1.3977\n",
            "Epoch 57/300\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 333ms/step - accuracy: 0.5958 - loss: 1.1593 - val_accuracy: 0.3333 - val_loss: 1.3862\n",
            "Epoch 58/300\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 326ms/step - accuracy: 0.5686 - loss: 1.1550 - val_accuracy: 0.3492 - val_loss: 1.3781\n",
            "Epoch 59/300\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 341ms/step - accuracy: 0.5355 - loss: 1.1708 - val_accuracy: 0.3016 - val_loss: 1.4058\n",
            "Epoch 60/300\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 345ms/step - accuracy: 0.5599 - loss: 1.1630 - val_accuracy: 0.3175 - val_loss: 1.3892\n",
            "Epoch 61/300\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 330ms/step - accuracy: 0.5266 - loss: 1.1630 - val_accuracy: 0.3175 - val_loss: 1.3819\n",
            "Epoch 62/300\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 337ms/step - accuracy: 0.5435 - loss: 1.1634 - val_accuracy: 0.2540 - val_loss: 1.3988\n",
            "Epoch 63/300\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 520ms/step - accuracy: 0.5998 - loss: 1.1490 - val_accuracy: 0.3016 - val_loss: 1.3928\n",
            "Epoch 64/300\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 321ms/step - accuracy: 0.5863 - loss: 1.1541 - val_accuracy: 0.3016 - val_loss: 1.4013\n",
            "Epoch 65/300\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 293ms/step - accuracy: 0.5498 - loss: 1.1542 - val_accuracy: 0.3175 - val_loss: 1.3881\n",
            "Epoch 66/300\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 331ms/step - accuracy: 0.5745 - loss: 1.1410 - val_accuracy: 0.3016 - val_loss: 1.4018\n",
            "Epoch 67/300\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 338ms/step - accuracy: 0.5902 - loss: 1.1233 - val_accuracy: 0.3016 - val_loss: 1.3964\n",
            "Epoch 68/300\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 300ms/step - accuracy: 0.5878 - loss: 1.1399 - val_accuracy: 0.3016 - val_loss: 1.3952\n",
            "Epoch 69/300\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 318ms/step - accuracy: 0.5799 - loss: 1.1281 - val_accuracy: 0.2857 - val_loss: 1.4014\n",
            "Epoch 70/300\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 340ms/step - accuracy: 0.6313 - loss: 1.1146 - val_accuracy: 0.2698 - val_loss: 1.3991\n",
            "Epoch 71/300\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 341ms/step - accuracy: 0.5231 - loss: 1.1455 - val_accuracy: 0.3333 - val_loss: 1.3977\n",
            "Epoch 72/300\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 339ms/step - accuracy: 0.5785 - loss: 1.1199 - val_accuracy: 0.3016 - val_loss: 1.4022\n",
            "Epoch 73/300\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 329ms/step - accuracy: 0.6072 - loss: 1.1203 - val_accuracy: 0.2857 - val_loss: 1.4081\n",
            "Epoch 74/300\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 566ms/step - accuracy: 0.6324 - loss: 1.1044 - val_accuracy: 0.3016 - val_loss: 1.3955\n",
            "Epoch 75/300\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 331ms/step - accuracy: 0.5625 - loss: 1.1227 - val_accuracy: 0.2857 - val_loss: 1.4080\n",
            "Epoch 76/300\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 334ms/step - accuracy: 0.6408 - loss: 1.0999 - val_accuracy: 0.2857 - val_loss: 1.4157\n",
            "Epoch 77/300\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 454ms/step - accuracy: 0.6058 - loss: 1.1190 - val_accuracy: 0.2698 - val_loss: 1.4015\n",
            "Epoch 78/300\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 528ms/step - accuracy: 0.6045 - loss: 1.0981 - val_accuracy: 0.2857 - val_loss: 1.4097\n",
            "Epoch 79/300\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 314ms/step - accuracy: 0.6001 - loss: 1.0887 - val_accuracy: 0.2857 - val_loss: 1.4032\n",
            "Epoch 80/300\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 328ms/step - accuracy: 0.5912 - loss: 1.0897 - val_accuracy: 0.3175 - val_loss: 1.4098\n",
            "Epoch 81/300\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 498ms/step - accuracy: 0.6321 - loss: 1.0786 - val_accuracy: 0.2857 - val_loss: 1.4181\n",
            "Epoch 82/300\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 332ms/step - accuracy: 0.6758 - loss: 1.0816 - val_accuracy: 0.2698 - val_loss: 1.4149\n",
            "Epoch 83/300\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 343ms/step - accuracy: 0.6091 - loss: 1.0813 - val_accuracy: 0.3016 - val_loss: 1.4076\n",
            "Epoch 84/300\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 597ms/step - accuracy: 0.5959 - loss: 1.0837 - val_accuracy: 0.2540 - val_loss: 1.4286\n",
            "Epoch 85/300\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 366ms/step - accuracy: 0.6273 - loss: 1.0698 - val_accuracy: 0.2540 - val_loss: 1.4087\n",
            "Epoch 86/300\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 325ms/step - accuracy: 0.6017 - loss: 1.0533 - val_accuracy: 0.3016 - val_loss: 1.4162\n",
            "Epoch 87/300\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 386ms/step - accuracy: 0.6233 - loss: 1.0547 - val_accuracy: 0.2540 - val_loss: 1.4233\n",
            "Epoch 88/300\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 602ms/step - accuracy: 0.5916 - loss: 1.0927 - val_accuracy: 0.2698 - val_loss: 1.4239\n",
            "Epoch 89/300\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 308ms/step - accuracy: 0.6734 - loss: 1.0408 - val_accuracy: 0.3016 - val_loss: 1.4151\n",
            "Epoch 90/300\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 319ms/step - accuracy: 0.6506 - loss: 1.0517 - val_accuracy: 0.2540 - val_loss: 1.4188\n",
            "Epoch 91/300\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 336ms/step - accuracy: 0.6488 - loss: 1.0638 - val_accuracy: 0.2857 - val_loss: 1.4230\n",
            "Epoch 92/300\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 401ms/step - accuracy: 0.6009 - loss: 1.0694 - val_accuracy: 0.2381 - val_loss: 1.4170\n",
            "Epoch 93/300\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 628ms/step - accuracy: 0.6342 - loss: 1.0730 - val_accuracy: 0.2698 - val_loss: 1.4317\n",
            "Epoch 94/300\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 325ms/step - accuracy: 0.6084 - loss: 1.0786 - val_accuracy: 0.2540 - val_loss: 1.4269\n",
            "Epoch 95/300\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 320ms/step - accuracy: 0.6452 - loss: 1.0423 - val_accuracy: 0.2540 - val_loss: 1.4275\n",
            "Epoch 96/300\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 349ms/step - accuracy: 0.6808 - loss: 1.0319 - val_accuracy: 0.2698 - val_loss: 1.4249\n",
            "Epoch 97/300\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 344ms/step - accuracy: 0.5838 - loss: 1.0755 - val_accuracy: 0.2857 - val_loss: 1.4378\n",
            "Epoch 98/300\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 351ms/step - accuracy: 0.6857 - loss: 1.0122 - val_accuracy: 0.1905 - val_loss: 1.4251\n",
            "Epoch 99/300\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 309ms/step - accuracy: 0.6197 - loss: 1.0362 - val_accuracy: 0.2540 - val_loss: 1.4414\n",
            "Epoch 100/300\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 360ms/step - accuracy: 0.6692 - loss: 1.0291 - val_accuracy: 0.2381 - val_loss: 1.4231\n",
            "Epoch 101/300\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 312ms/step - accuracy: 0.6405 - loss: 1.0289 - val_accuracy: 0.2698 - val_loss: 1.4456\n",
            "Epoch 102/300\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 322ms/step - accuracy: 0.6573 - loss: 1.0132 - val_accuracy: 0.2698 - val_loss: 1.4504\n",
            "Epoch 103/300\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 312ms/step - accuracy: 0.6517 - loss: 1.0160 - val_accuracy: 0.2381 - val_loss: 1.4318\n",
            "Epoch 104/300\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 328ms/step - accuracy: 0.6529 - loss: 1.0090 - val_accuracy: 0.2698 - val_loss: 1.4548\n",
            "Epoch 105/300\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 384ms/step - accuracy: 0.6693 - loss: 1.0117 - val_accuracy: 0.2381 - val_loss: 1.4310\n",
            "Epoch 106/300\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 333ms/step - accuracy: 0.7159 - loss: 0.9971 - val_accuracy: 0.2381 - val_loss: 1.4378\n",
            "Epoch 107/300\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 329ms/step - accuracy: 0.6434 - loss: 1.0270 - val_accuracy: 0.2857 - val_loss: 1.4604\n",
            "Epoch 108/300\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 596ms/step - accuracy: 0.6525 - loss: 1.0058 - val_accuracy: 0.2381 - val_loss: 1.4403\n",
            "Epoch 109/300\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 339ms/step - accuracy: 0.6808 - loss: 1.0096 - val_accuracy: 0.2381 - val_loss: 1.4429\n",
            "Epoch 110/300\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 342ms/step - accuracy: 0.6653 - loss: 0.9992 - val_accuracy: 0.2222 - val_loss: 1.4510\n",
            "Epoch 111/300\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 363ms/step - accuracy: 0.6876 - loss: 0.9943 - val_accuracy: 0.2698 - val_loss: 1.4510\n",
            "Epoch 112/300\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 331ms/step - accuracy: 0.6940 - loss: 1.0009 - val_accuracy: 0.2222 - val_loss: 1.4482\n",
            "Epoch 113/300\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 343ms/step - accuracy: 0.6768 - loss: 1.0127 - val_accuracy: 0.2698 - val_loss: 1.4634\n",
            "Epoch 114/300\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 342ms/step - accuracy: 0.6539 - loss: 1.0095 - val_accuracy: 0.2063 - val_loss: 1.4414\n",
            "Epoch 115/300\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 458ms/step - accuracy: 0.6931 - loss: 0.9686 - val_accuracy: 0.2857 - val_loss: 1.4691\n",
            "Epoch 116/300\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 355ms/step - accuracy: 0.7015 - loss: 0.9746 - val_accuracy: 0.2222 - val_loss: 1.4557\n",
            "Epoch 117/300\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 343ms/step - accuracy: 0.7057 - loss: 0.9537 - val_accuracy: 0.2063 - val_loss: 1.4455\n",
            "Epoch 118/300\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 322ms/step - accuracy: 0.7099 - loss: 0.9579 - val_accuracy: 0.3175 - val_loss: 1.4876\n",
            "Epoch 119/300\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 537ms/step - accuracy: 0.6894 - loss: 0.9655 - val_accuracy: 0.2381 - val_loss: 1.4614\n",
            "Epoch 120/300\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 347ms/step - accuracy: 0.6640 - loss: 0.9870 - val_accuracy: 0.2222 - val_loss: 1.4578\n",
            "Epoch 121/300\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 315ms/step - accuracy: 0.6835 - loss: 0.9521 - val_accuracy: 0.3016 - val_loss: 1.4753\n",
            "Epoch 122/300\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 430ms/step - accuracy: 0.7127 - loss: 0.9647 - val_accuracy: 0.2222 - val_loss: 1.4596\n",
            "Epoch 123/300\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 516ms/step - accuracy: 0.7080 - loss: 0.9591 - val_accuracy: 0.2063 - val_loss: 1.4608\n",
            "Epoch 124/300\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 317ms/step - accuracy: 0.7220 - loss: 0.9621 - val_accuracy: 0.2381 - val_loss: 1.4749\n",
            "Epoch 125/300\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 313ms/step - accuracy: 0.6924 - loss: 0.9582 - val_accuracy: 0.2540 - val_loss: 1.4810\n",
            "Epoch 126/300\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 321ms/step - accuracy: 0.7383 - loss: 0.9508 - val_accuracy: 0.2222 - val_loss: 1.4660\n",
            "Epoch 127/300\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 518ms/step - accuracy: 0.7176 - loss: 0.9511 - val_accuracy: 0.2222 - val_loss: 1.4765\n",
            "Epoch 128/300\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 326ms/step - accuracy: 0.6895 - loss: 0.9460 - val_accuracy: 0.2381 - val_loss: 1.4824\n",
            "Epoch 129/300\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 329ms/step - accuracy: 0.7603 - loss: 0.9028 - val_accuracy: 0.2063 - val_loss: 1.4737\n",
            "Epoch 130/300\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 396ms/step - accuracy: 0.6692 - loss: 0.9487 - val_accuracy: 0.2381 - val_loss: 1.4771\n",
            "Epoch 131/300\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 328ms/step - accuracy: 0.6925 - loss: 0.9303 - val_accuracy: 0.2222 - val_loss: 1.4834\n",
            "Epoch 132/300\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 315ms/step - accuracy: 0.6851 - loss: 0.9313 - val_accuracy: 0.2381 - val_loss: 1.4782\n",
            "Epoch 133/300\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 352ms/step - accuracy: 0.6850 - loss: 0.9454 - val_accuracy: 0.2540 - val_loss: 1.4793\n",
            "Epoch 134/300\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 434ms/step - accuracy: 0.7157 - loss: 0.9463 - val_accuracy: 0.2540 - val_loss: 1.4987\n",
            "Epoch 135/300\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 318ms/step - accuracy: 0.7169 - loss: 0.9069 - val_accuracy: 0.2222 - val_loss: 1.4821\n",
            "Epoch 136/300\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 324ms/step - accuracy: 0.7061 - loss: 0.9163 - val_accuracy: 0.2698 - val_loss: 1.4888\n",
            "Epoch 137/300\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 409ms/step - accuracy: 0.7199 - loss: 0.9443 - val_accuracy: 0.2381 - val_loss: 1.4939\n",
            "Epoch 138/300\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 526ms/step - accuracy: 0.7108 - loss: 0.9076 - val_accuracy: 0.2222 - val_loss: 1.4872\n",
            "Epoch 139/300\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 324ms/step - accuracy: 0.7110 - loss: 0.9205 - val_accuracy: 0.2698 - val_loss: 1.4950\n",
            "Epoch 140/300\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 337ms/step - accuracy: 0.7491 - loss: 0.9265 - val_accuracy: 0.2381 - val_loss: 1.4916\n",
            "Epoch 141/300\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 636ms/step - accuracy: 0.7437 - loss: 0.8833 - val_accuracy: 0.2381 - val_loss: 1.5128\n",
            "Epoch 142/300\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 350ms/step - accuracy: 0.7111 - loss: 0.9165 - val_accuracy: 0.2063 - val_loss: 1.4915\n",
            "Epoch 143/300\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 346ms/step - accuracy: 0.7460 - loss: 0.9171 - val_accuracy: 0.2222 - val_loss: 1.4981\n",
            "Epoch 144/300\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 587ms/step - accuracy: 0.7235 - loss: 0.9116 - val_accuracy: 0.2381 - val_loss: 1.4990\n",
            "Epoch 145/300\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 336ms/step - accuracy: 0.7422 - loss: 0.8955 - val_accuracy: 0.2222 - val_loss: 1.5008\n",
            "Epoch 146/300\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 346ms/step - accuracy: 0.7607 - loss: 0.8999 - val_accuracy: 0.2381 - val_loss: 1.5133\n",
            "Epoch 147/300\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 507ms/step - accuracy: 0.7493 - loss: 0.8974 - val_accuracy: 0.2063 - val_loss: 1.4971\n",
            "Epoch 148/300\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 502ms/step - accuracy: 0.6976 - loss: 0.9278 - val_accuracy: 0.2540 - val_loss: 1.5410\n",
            "Epoch 149/300\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 328ms/step - accuracy: 0.7419 - loss: 0.8935 - val_accuracy: 0.2222 - val_loss: 1.4895\n",
            "Epoch 150/300\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 338ms/step - accuracy: 0.7596 - loss: 0.8880 - val_accuracy: 0.2222 - val_loss: 1.5286\n",
            "Epoch 151/300\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 484ms/step - accuracy: 0.7430 - loss: 0.8948 - val_accuracy: 0.2381 - val_loss: 1.5235\n",
            "Epoch 152/300\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 345ms/step - accuracy: 0.7696 - loss: 0.8546 - val_accuracy: 0.1905 - val_loss: 1.5020\n",
            "Epoch 153/300\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 303ms/step - accuracy: 0.7462 - loss: 0.8903 - val_accuracy: 0.2222 - val_loss: 1.5073\n",
            "Epoch 154/300\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 471ms/step - accuracy: 0.7756 - loss: 0.8706 - val_accuracy: 0.2222 - val_loss: 1.5309\n",
            "Epoch 155/300\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 321ms/step - accuracy: 0.7347 - loss: 0.8801 - val_accuracy: 0.2063 - val_loss: 1.5145\n",
            "Epoch 156/300\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 318ms/step - accuracy: 0.7689 - loss: 0.8614 - val_accuracy: 0.2222 - val_loss: 1.5230\n",
            "Epoch 157/300\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 336ms/step - accuracy: 0.7239 - loss: 0.8871 - val_accuracy: 0.2381 - val_loss: 1.5208\n",
            "Epoch 158/300\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 634ms/step - accuracy: 0.7807 - loss: 0.8679 - val_accuracy: 0.2381 - val_loss: 1.5374\n",
            "Epoch 159/300\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 333ms/step - accuracy: 0.7789 - loss: 0.8541 - val_accuracy: 0.1905 - val_loss: 1.5151\n",
            "Epoch 160/300\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 317ms/step - accuracy: 0.7184 - loss: 0.8979 - val_accuracy: 0.2381 - val_loss: 1.5405\n",
            "Epoch 161/300\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 460ms/step - accuracy: 0.7408 - loss: 0.8741 - val_accuracy: 0.2222 - val_loss: 1.5262\n",
            "Epoch 162/300\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 536ms/step - accuracy: 0.7398 - loss: 0.8730 - val_accuracy: 0.2222 - val_loss: 1.5252\n",
            "Epoch 163/300\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 331ms/step - accuracy: 0.7713 - loss: 0.8490 - val_accuracy: 0.2222 - val_loss: 1.5473\n",
            "Epoch 164/300\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 341ms/step - accuracy: 0.7744 - loss: 0.8667 - val_accuracy: 0.2222 - val_loss: 1.5318\n",
            "Epoch 165/300\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 463ms/step - accuracy: 0.7856 - loss: 0.8254 - val_accuracy: 0.2222 - val_loss: 1.5355\n",
            "Epoch 166/300\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 487ms/step - accuracy: 0.7805 - loss: 0.8495 - val_accuracy: 0.2381 - val_loss: 1.5465\n",
            "Epoch 167/300\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 331ms/step - accuracy: 0.7676 - loss: 0.8369 - val_accuracy: 0.2222 - val_loss: 1.5392\n",
            "Epoch 168/300\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 339ms/step - accuracy: 0.7916 - loss: 0.8542 - val_accuracy: 0.2222 - val_loss: 1.5469\n",
            "Epoch 169/300\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 512ms/step - accuracy: 0.7675 - loss: 0.8301 - val_accuracy: 0.2063 - val_loss: 1.5385\n",
            "Epoch 170/300\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 485ms/step - accuracy: 0.7686 - loss: 0.8316 - val_accuracy: 0.2222 - val_loss: 1.5486\n",
            "Epoch 171/300\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 346ms/step - accuracy: 0.7713 - loss: 0.8416 - val_accuracy: 0.2222 - val_loss: 1.5536\n",
            "Epoch 172/300\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 358ms/step - accuracy: 0.7639 - loss: 0.8502 - val_accuracy: 0.1905 - val_loss: 1.5407\n",
            "Epoch 173/300\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 421ms/step - accuracy: 0.7631 - loss: 0.8495 - val_accuracy: 0.2063 - val_loss: 1.5527\n",
            "Epoch 174/300\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 612ms/step - accuracy: 0.7994 - loss: 0.8299 - val_accuracy: 0.2222 - val_loss: 1.5586\n",
            "Epoch 175/300\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 325ms/step - accuracy: 0.7651 - loss: 0.8316 - val_accuracy: 0.2222 - val_loss: 1.5486\n",
            "Epoch 176/300\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 339ms/step - accuracy: 0.7556 - loss: 0.8359 - val_accuracy: 0.2222 - val_loss: 1.5532\n",
            "Epoch 177/300\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 450ms/step - accuracy: 0.7798 - loss: 0.8262 - val_accuracy: 0.2222 - val_loss: 1.5571\n",
            "Epoch 178/300\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 335ms/step - accuracy: 0.8272 - loss: 0.7692 - val_accuracy: 0.2381 - val_loss: 1.5665\n",
            "Epoch 179/300\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 329ms/step - accuracy: 0.7732 - loss: 0.8227 - val_accuracy: 0.2222 - val_loss: 1.5791\n",
            "Epoch 180/300\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 622ms/step - accuracy: 0.7406 - loss: 0.8456 - val_accuracy: 0.1905 - val_loss: 1.5541\n",
            "Epoch 181/300\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 319ms/step - accuracy: 0.8069 - loss: 0.7919 - val_accuracy: 0.2222 - val_loss: 1.5706\n",
            "Epoch 182/300\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 332ms/step - accuracy: 0.8024 - loss: 0.8100 - val_accuracy: 0.2222 - val_loss: 1.5642\n",
            "Epoch 183/300\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 330ms/step - accuracy: 0.7792 - loss: 0.8173 - val_accuracy: 0.2063 - val_loss: 1.5758\n",
            "Epoch 184/300\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 537ms/step - accuracy: 0.7967 - loss: 0.8146 - val_accuracy: 0.2063 - val_loss: 1.5644\n",
            "Epoch 185/300\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 417ms/step - accuracy: 0.7831 - loss: 0.7990 - val_accuracy: 0.2222 - val_loss: 1.5808\n",
            "Epoch 186/300\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 336ms/step - accuracy: 0.7835 - loss: 0.7935 - val_accuracy: 0.1746 - val_loss: 1.5675\n",
            "Epoch 187/300\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 326ms/step - accuracy: 0.7697 - loss: 0.8192 - val_accuracy: 0.2063 - val_loss: 1.5808\n",
            "Epoch 188/300\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 434ms/step - accuracy: 0.8172 - loss: 0.7544 - val_accuracy: 0.2222 - val_loss: 1.5776\n",
            "Epoch 189/300\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 325ms/step - accuracy: 0.8141 - loss: 0.7746 - val_accuracy: 0.2063 - val_loss: 1.5755\n",
            "Epoch 190/300\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 503ms/step - accuracy: 0.7667 - loss: 0.8109 - val_accuracy: 0.1587 - val_loss: 1.5700\n",
            "Epoch 191/300\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 497ms/step - accuracy: 0.8108 - loss: 0.7724 - val_accuracy: 0.2063 - val_loss: 1.6100\n",
            "Epoch 192/300\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 339ms/step - accuracy: 0.7730 - loss: 0.7999 - val_accuracy: 0.1905 - val_loss: 1.5799\n",
            "Epoch 193/300\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 348ms/step - accuracy: 0.8096 - loss: 0.7775 - val_accuracy: 0.2222 - val_loss: 1.5929\n",
            "Epoch 194/300\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 493ms/step - accuracy: 0.8106 - loss: 0.7570 - val_accuracy: 0.1905 - val_loss: 1.5885\n",
            "Epoch 195/300\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 498ms/step - accuracy: 0.8088 - loss: 0.7588 - val_accuracy: 0.2222 - val_loss: 1.5934\n",
            "Epoch 196/300\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 330ms/step - accuracy: 0.7926 - loss: 0.7847 - val_accuracy: 0.1905 - val_loss: 1.5894\n",
            "Epoch 197/300\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 337ms/step - accuracy: 0.8290 - loss: 0.7650 - val_accuracy: 0.2063 - val_loss: 1.6099\n",
            "Epoch 198/300\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 396ms/step - accuracy: 0.7793 - loss: 0.7798 - val_accuracy: 0.1905 - val_loss: 1.5923\n",
            "Epoch 199/300\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 331ms/step - accuracy: 0.7576 - loss: 0.7841 - val_accuracy: 0.2063 - val_loss: 1.6029\n",
            "Epoch 200/300\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 342ms/step - accuracy: 0.8142 - loss: 0.7478 - val_accuracy: 0.2222 - val_loss: 1.6053\n",
            "Epoch 201/300\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 353ms/step - accuracy: 0.8192 - loss: 0.7388 - val_accuracy: 0.1746 - val_loss: 1.6007\n",
            "Epoch 202/300\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 345ms/step - accuracy: 0.8233 - loss: 0.7375 - val_accuracy: 0.2063 - val_loss: 1.6093\n",
            "Epoch 203/300\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 351ms/step - accuracy: 0.7990 - loss: 0.7582 - val_accuracy: 0.1905 - val_loss: 1.6118\n",
            "Epoch 204/300\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 369ms/step - accuracy: 0.8177 - loss: 0.7570 - val_accuracy: 0.2063 - val_loss: 1.6063\n",
            "Epoch 205/300\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 384ms/step - accuracy: 0.8144 - loss: 0.7360 - val_accuracy: 0.2063 - val_loss: 1.6170\n",
            "Epoch 206/300\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 318ms/step - accuracy: 0.8355 - loss: 0.7403 - val_accuracy: 0.2063 - val_loss: 1.6070\n",
            "Epoch 207/300\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 371ms/step - accuracy: 0.8409 - loss: 0.7298 - val_accuracy: 0.2222 - val_loss: 1.6333\n",
            "Epoch 208/300\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 352ms/step - accuracy: 0.8268 - loss: 0.7241 - val_accuracy: 0.1905 - val_loss: 1.6090\n",
            "Epoch 209/300\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 533ms/step - accuracy: 0.8289 - loss: 0.7487 - val_accuracy: 0.1905 - val_loss: 1.6240\n",
            "Epoch 210/300\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 429ms/step - accuracy: 0.8195 - loss: 0.7309 - val_accuracy: 0.2063 - val_loss: 1.6318\n",
            "Epoch 211/300\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 348ms/step - accuracy: 0.8097 - loss: 0.7365 - val_accuracy: 0.2063 - val_loss: 1.6181\n",
            "Epoch 212/300\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 321ms/step - accuracy: 0.8149 - loss: 0.7320 - val_accuracy: 0.1587 - val_loss: 1.6200\n",
            "Epoch 213/300\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 330ms/step - accuracy: 0.8319 - loss: 0.7193 - val_accuracy: 0.1905 - val_loss: 1.6363\n",
            "Epoch 214/300\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 595ms/step - accuracy: 0.8299 - loss: 0.7291 - val_accuracy: 0.1905 - val_loss: 1.6231\n",
            "Epoch 215/300\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 344ms/step - accuracy: 0.8279 - loss: 0.7411 - val_accuracy: 0.2063 - val_loss: 1.6353\n",
            "Epoch 216/300\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 316ms/step - accuracy: 0.8380 - loss: 0.7226 - val_accuracy: 0.1905 - val_loss: 1.6250\n",
            "Epoch 217/300\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 378ms/step - accuracy: 0.8307 - loss: 0.7303 - val_accuracy: 0.2222 - val_loss: 1.6515\n",
            "Epoch 218/300\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 410ms/step - accuracy: 0.8096 - loss: 0.7364 - val_accuracy: 0.1746 - val_loss: 1.6301\n",
            "Epoch 219/300\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 375ms/step - accuracy: 0.7739 - loss: 0.7610 - val_accuracy: 0.2063 - val_loss: 1.6307\n",
            "Epoch 220/300\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 361ms/step - accuracy: 0.8235 - loss: 0.6995 - val_accuracy: 0.2063 - val_loss: 1.6558\n",
            "Epoch 221/300\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 625ms/step - accuracy: 0.8325 - loss: 0.6969 - val_accuracy: 0.1587 - val_loss: 1.6277\n",
            "Epoch 222/300\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 345ms/step - accuracy: 0.8533 - loss: 0.7019 - val_accuracy: 0.2063 - val_loss: 1.6475\n",
            "Epoch 223/300\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 343ms/step - accuracy: 0.8467 - loss: 0.6941 - val_accuracy: 0.1905 - val_loss: 1.6417\n",
            "Epoch 224/300\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 372ms/step - accuracy: 0.8463 - loss: 0.6837 - val_accuracy: 0.1905 - val_loss: 1.6585\n",
            "Epoch 225/300\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 628ms/step - accuracy: 0.8139 - loss: 0.7351 - val_accuracy: 0.2063 - val_loss: 1.6404\n",
            "Epoch 226/300\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 371ms/step - accuracy: 0.8556 - loss: 0.7000 - val_accuracy: 0.1905 - val_loss: 1.6494\n",
            "Epoch 227/300\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 336ms/step - accuracy: 0.8507 - loss: 0.6956 - val_accuracy: 0.2063 - val_loss: 1.6683\n",
            "Epoch 228/300\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 364ms/step - accuracy: 0.8222 - loss: 0.6984 - val_accuracy: 0.1587 - val_loss: 1.6418\n",
            "Epoch 229/300\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 523ms/step - accuracy: 0.8274 - loss: 0.6864 - val_accuracy: 0.2063 - val_loss: 1.6809\n",
            "Epoch 230/300\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 370ms/step - accuracy: 0.8300 - loss: 0.6983 - val_accuracy: 0.2063 - val_loss: 1.6671\n",
            "Epoch 231/300\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 334ms/step - accuracy: 0.8445 - loss: 0.6773 - val_accuracy: 0.1746 - val_loss: 1.6498\n",
            "Epoch 232/300\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 394ms/step - accuracy: 0.8303 - loss: 0.6716 - val_accuracy: 0.1905 - val_loss: 1.6665\n",
            "Epoch 233/300\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 360ms/step - accuracy: 0.8577 - loss: 0.6735 - val_accuracy: 0.2063 - val_loss: 1.6746\n",
            "Epoch 234/300\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 333ms/step - accuracy: 0.8513 - loss: 0.6631 - val_accuracy: 0.1905 - val_loss: 1.6690\n",
            "Epoch 235/300\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 334ms/step - accuracy: 0.8373 - loss: 0.6887 - val_accuracy: 0.1905 - val_loss: 1.6677\n",
            "Epoch 236/300\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 409ms/step - accuracy: 0.8625 - loss: 0.7023 - val_accuracy: 0.1905 - val_loss: 1.6719\n",
            "Epoch 237/300\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 350ms/step - accuracy: 0.8548 - loss: 0.6822 - val_accuracy: 0.1587 - val_loss: 1.6679\n",
            "Epoch 238/300\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 341ms/step - accuracy: 0.8310 - loss: 0.7028 - val_accuracy: 0.2063 - val_loss: 1.6878\n",
            "Epoch 239/300\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 348ms/step - accuracy: 0.8259 - loss: 0.6771 - val_accuracy: 0.1905 - val_loss: 1.6734\n",
            "Epoch 240/300\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 547ms/step - accuracy: 0.8412 - loss: 0.6921 - val_accuracy: 0.1905 - val_loss: 1.6790\n",
            "Epoch 241/300\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 347ms/step - accuracy: 0.8320 - loss: 0.6819 - val_accuracy: 0.1746 - val_loss: 1.6807\n",
            "Epoch 242/300\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 318ms/step - accuracy: 0.8317 - loss: 0.6822 - val_accuracy: 0.2063 - val_loss: 1.6839\n",
            "Epoch 243/300\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 350ms/step - accuracy: 0.8483 - loss: 0.6663 - val_accuracy: 0.2063 - val_loss: 1.6799\n",
            "Epoch 244/300\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 538ms/step - accuracy: 0.8644 - loss: 0.6620 - val_accuracy: 0.1905 - val_loss: 1.6878\n",
            "Epoch 245/300\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 334ms/step - accuracy: 0.8522 - loss: 0.6554 - val_accuracy: 0.1905 - val_loss: 1.7047\n",
            "Epoch 246/300\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 347ms/step - accuracy: 0.8284 - loss: 0.6909 - val_accuracy: 0.1905 - val_loss: 1.6863\n",
            "Epoch 247/300\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 558ms/step - accuracy: 0.8475 - loss: 0.6765 - val_accuracy: 0.1905 - val_loss: 1.6962\n",
            "Epoch 248/300\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 349ms/step - accuracy: 0.8346 - loss: 0.6658 - val_accuracy: 0.1905 - val_loss: 1.6965\n",
            "Epoch 249/300\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 348ms/step - accuracy: 0.8619 - loss: 0.6614 - val_accuracy: 0.1746 - val_loss: 1.7001\n",
            "Epoch 250/300\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 332ms/step - accuracy: 0.8620 - loss: 0.6624 - val_accuracy: 0.1746 - val_loss: 1.6924\n",
            "Epoch 251/300\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 366ms/step - accuracy: 0.8709 - loss: 0.6506 - val_accuracy: 0.2063 - val_loss: 1.7131\n",
            "Epoch 252/300\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 326ms/step - accuracy: 0.8415 - loss: 0.6577 - val_accuracy: 0.1746 - val_loss: 1.7042\n",
            "Epoch 253/300\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 340ms/step - accuracy: 0.8448 - loss: 0.6602 - val_accuracy: 0.1905 - val_loss: 1.7047\n",
            "Epoch 254/300\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 551ms/step - accuracy: 0.8514 - loss: 0.6417 - val_accuracy: 0.1587 - val_loss: 1.6963\n",
            "Epoch 255/300\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 404ms/step - accuracy: 0.8612 - loss: 0.6425 - val_accuracy: 0.1905 - val_loss: 1.7240\n",
            "Epoch 256/300\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 356ms/step - accuracy: 0.8957 - loss: 0.6201 - val_accuracy: 0.1905 - val_loss: 1.7003\n",
            "Epoch 257/300\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 329ms/step - accuracy: 0.8486 - loss: 0.6515 - val_accuracy: 0.1746 - val_loss: 1.7194\n",
            "Epoch 258/300\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 529ms/step - accuracy: 0.8286 - loss: 0.6376 - val_accuracy: 0.1905 - val_loss: 1.7139\n",
            "Epoch 259/300\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 428ms/step - accuracy: 0.8568 - loss: 0.6451 - val_accuracy: 0.1746 - val_loss: 1.7161\n",
            "Epoch 260/300\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 351ms/step - accuracy: 0.8289 - loss: 0.6260 - val_accuracy: 0.2063 - val_loss: 1.7154\n",
            "Epoch 261/300\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 324ms/step - accuracy: 0.8710 - loss: 0.6318 - val_accuracy: 0.2063 - val_loss: 1.7199\n",
            "Epoch 262/300\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 547ms/step - accuracy: 0.8632 - loss: 0.6345 - val_accuracy: 0.1746 - val_loss: 1.7255\n",
            "Epoch 263/300\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 484ms/step - accuracy: 0.8718 - loss: 0.6199 - val_accuracy: 0.1746 - val_loss: 1.7148\n",
            "Epoch 264/300\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 357ms/step - accuracy: 0.8420 - loss: 0.6304 - val_accuracy: 0.1905 - val_loss: 1.7345\n",
            "Epoch 265/300\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 331ms/step - accuracy: 0.8456 - loss: 0.6278 - val_accuracy: 0.1746 - val_loss: 1.7214\n",
            "Epoch 266/300\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 552ms/step - accuracy: 0.8555 - loss: 0.6141 - val_accuracy: 0.1746 - val_loss: 1.7352\n",
            "Epoch 267/300\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 440ms/step - accuracy: 0.8528 - loss: 0.6235 - val_accuracy: 0.1746 - val_loss: 1.7204\n",
            "Epoch 268/300\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 343ms/step - accuracy: 0.8494 - loss: 0.6355 - val_accuracy: 0.2063 - val_loss: 1.7387\n",
            "Epoch 269/300\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 333ms/step - accuracy: 0.8701 - loss: 0.6367 - val_accuracy: 0.1746 - val_loss: 1.7305\n",
            "Epoch 270/300\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 556ms/step - accuracy: 0.8632 - loss: 0.6095 - val_accuracy: 0.1746 - val_loss: 1.7430\n",
            "Epoch 271/300\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 322ms/step - accuracy: 0.8787 - loss: 0.6229 - val_accuracy: 0.1905 - val_loss: 1.7401\n",
            "Epoch 272/300\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 348ms/step - accuracy: 0.8976 - loss: 0.6217 - val_accuracy: 0.1746 - val_loss: 1.7376\n",
            "Epoch 273/300\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 350ms/step - accuracy: 0.8751 - loss: 0.5888 - val_accuracy: 0.1746 - val_loss: 1.7570\n",
            "Epoch 274/300\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 624ms/step - accuracy: 0.8429 - loss: 0.6159 - val_accuracy: 0.1905 - val_loss: 1.7431\n",
            "Epoch 275/300\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 350ms/step - accuracy: 0.8914 - loss: 0.6015 - val_accuracy: 0.1746 - val_loss: 1.7567\n",
            "Epoch 276/300\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 358ms/step - accuracy: 0.8655 - loss: 0.5893 - val_accuracy: 0.1746 - val_loss: 1.7455\n",
            "Epoch 277/300\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 419ms/step - accuracy: 0.8913 - loss: 0.6082 - val_accuracy: 0.1905 - val_loss: 1.7456\n",
            "Epoch 278/300\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 362ms/step - accuracy: 0.8727 - loss: 0.6040 - val_accuracy: 0.1746 - val_loss: 1.7629\n",
            "Epoch 279/300\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 321ms/step - accuracy: 0.8865 - loss: 0.5828 - val_accuracy: 0.1746 - val_loss: 1.7616\n",
            "Epoch 280/300\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 350ms/step - accuracy: 0.8729 - loss: 0.5879 - val_accuracy: 0.1905 - val_loss: 1.7454\n",
            "Epoch 281/300\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 582ms/step - accuracy: 0.8804 - loss: 0.5749 - val_accuracy: 0.1746 - val_loss: 1.7675\n",
            "Epoch 282/300\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 446ms/step - accuracy: 0.8914 - loss: 0.5663 - val_accuracy: 0.1746 - val_loss: 1.7589\n",
            "Epoch 283/300\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 349ms/step - accuracy: 0.9095 - loss: 0.5567 - val_accuracy: 0.1746 - val_loss: 1.7656\n",
            "Epoch 284/300\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 504ms/step - accuracy: 0.8924 - loss: 0.6056 - val_accuracy: 0.1905 - val_loss: 1.7637\n",
            "Epoch 285/300\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 511ms/step - accuracy: 0.8751 - loss: 0.6080 - val_accuracy: 0.1587 - val_loss: 1.7843\n",
            "Epoch 286/300\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 339ms/step - accuracy: 0.8816 - loss: 0.5842 - val_accuracy: 0.1905 - val_loss: 1.7779\n",
            "Epoch 287/300\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 351ms/step - accuracy: 0.8815 - loss: 0.5884 - val_accuracy: 0.1746 - val_loss: 1.7745\n",
            "Epoch 288/300\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 368ms/step - accuracy: 0.8475 - loss: 0.6062 - val_accuracy: 0.1746 - val_loss: 1.7715\n",
            "Epoch 289/300\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 564ms/step - accuracy: 0.8686 - loss: 0.5795 - val_accuracy: 0.1746 - val_loss: 1.7759\n",
            "Epoch 290/300\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 407ms/step - accuracy: 0.8862 - loss: 0.5700 - val_accuracy: 0.1746 - val_loss: 1.7838\n",
            "Epoch 291/300\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 356ms/step - accuracy: 0.8909 - loss: 0.5460 - val_accuracy: 0.1746 - val_loss: 1.7908\n",
            "Epoch 292/300\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 336ms/step - accuracy: 0.8907 - loss: 0.5757 - val_accuracy: 0.1587 - val_loss: 1.7781\n",
            "Epoch 293/300\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 535ms/step - accuracy: 0.8630 - loss: 0.5651 - val_accuracy: 0.1905 - val_loss: 1.7874\n",
            "Epoch 294/300\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 322ms/step - accuracy: 0.8921 - loss: 0.5651 - val_accuracy: 0.1746 - val_loss: 1.7969\n",
            "Epoch 295/300\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 319ms/step - accuracy: 0.8854 - loss: 0.5675 - val_accuracy: 0.1746 - val_loss: 1.7795\n",
            "Epoch 296/300\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 353ms/step - accuracy: 0.9083 - loss: 0.5665 - val_accuracy: 0.1746 - val_loss: 1.7905\n",
            "Epoch 297/300\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 558ms/step - accuracy: 0.8992 - loss: 0.5501 - val_accuracy: 0.1746 - val_loss: 1.8045\n",
            "Epoch 298/300\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 376ms/step - accuracy: 0.9124 - loss: 0.5982 - val_accuracy: 0.1905 - val_loss: 1.7986\n",
            "Epoch 299/300\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 363ms/step - accuracy: 0.9023 - loss: 0.5433 - val_accuracy: 0.1587 - val_loss: 1.8029\n",
            "Epoch 300/300\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 362ms/step - accuracy: 0.8555 - loss: 0.5983 - val_accuracy: 0.1746 - val_loss: 1.7966\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 417ms/step\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 247ms/step\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 256ms/step\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 266ms/step\n",
            "meta_training:\n",
            "Meta Model Accuracy: 0.7142857142857143\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from re import X\n",
        "# 提出\n",
        "import zipfile\n",
        "from PIL import Image\n",
        "from io import BytesIO\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "def load_test_data():\n",
        "    test_zip_path = '/content/drive/My Drive/Colab Notebooks/【練習問題】モノクロ顔画像の感情分類/test.zip'\n",
        "    with zipfile.ZipFile(test_zip_path, 'r') as z:\n",
        "        image_files = z.namelist()\n",
        "        images = []\n",
        "\n",
        "        for file_name in image_files:\n",
        "            with z.open(file_name) as img_file:\n",
        "                img = Image.open(BytesIO(img_file.read()))\n",
        "                img = img.resize((128, 120))\n",
        "                img = np.array(img)\n",
        "                images.append(img)\n",
        "\n",
        "    X_test = np.array(images)\n",
        "    X_test = X_test / 255.0\n",
        "    return X_test, image_files\n",
        "\n",
        "# テストデータの読み込み\n",
        "X_test, image_files = load_test_data()\n",
        "\n",
        "# ベースモデルの予測\n",
        "X_userid_test_preds = get_base_model_predictions(model_userid, X_test)\n",
        "X_pose_test_preds = get_base_model_predictions(model_pose, X_test)\n",
        "X_eyes_test_preds = get_base_model_predictions(model_eyes, X_test)\n",
        "X_expression_test_preds = get_base_model_predictions(model_expression, X_test)\n",
        "\n",
        "# ベースモデルの予測を統合\n",
        "X_meta_test = np.hstack([X_userid_test_preds, X_pose_test_preds, X_eyes_test_preds, X_expression_preds])\n",
        "\n",
        "# メタモデルで最終的な予測を行う\n",
        "y_meta_test_preds = meta_model.predict(X_meta_test)\n",
        "\n",
        "# 逆マッピングを作成\n",
        "reverse_replace_dict = {v: k for k, v in replace_dict.items()}\n",
        "\n",
        "# 予測結果を Pandas Series に変換\n",
        "y_meta_test_preds_series = pd.Series(y_meta_test_preds)\n",
        "\n",
        "# 逆マッピングを適用\n",
        "y_meta_test_preds_replaced = y_meta_test_preds_series.map(reverse_replace_dict)\n",
        "\n",
        "# リスト内の各文字列に対して test/ を削除する\n",
        "image_files = [filename.replace('test/', '') for filename in image_files]\n",
        "\n",
        "# 予測結果を投稿用のフォーマットに変換\n",
        "results_df = pd.DataFrame({\n",
        "    'ファイル名': image_files,\n",
        "    '予測した感情': y_meta_test_preds_replaced\n",
        "})\n",
        "\n",
        "# CSVファイルとして保存\n",
        "output_csv_path = '/content/sample_submit.csv'\n",
        "results_df.to_csv(output_csv_path, index=False, encoding='utf-8-sig')\n",
        "\n",
        "print(f'予測結果が{output_csv_path}に保存されました。')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ilniv-N7zAzF",
        "outputId": "f555ca77-870e-4be9-efc1-27bd905397dc"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 411ms/step\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 461ms/step\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 566ms/step\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 437ms/step\n",
            "予測結果が/content/sample_submit.csvに保存されました。\n"
          ]
        }
      ]
    }
  ]
}